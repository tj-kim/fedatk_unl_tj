{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiround UNL Attack Trimmed Mean other attacks\n",
    "\n",
    "Fig 6b \n",
    "\n",
    "##### Summary\n",
    "The function UNL_mix_other_attack\n",
    "can be used to perform label flip and random noise attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd to_base_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import General Libraries\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import FedEM based Libraries\n",
    "from utils.utils import *\n",
    "from utils.constants import *\n",
    "from utils.args import *\n",
    "from utils.util_notebooks import *\n",
    "from run_experiment import *\n",
    "from models import *\n",
    "\n",
    "# Import Transfer Attack\n",
    "from transfer_attacks.Personalized_NN import *\n",
    "from transfer_attacks.Params import *\n",
    "from transfer_attacks.Transferer import *\n",
    "from transfer_attacks.Args import *\n",
    "from transfer_attacks.TA_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 161.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:37<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Test Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "setting, num_user = \"FedAvg_adv\", 40\n",
    "\n",
    "try: # Skip loading if already loaded\n",
    "    aggregator\n",
    "except:\n",
    "    aggregator, clients, args_ = set_args(setting, num_user,  experiment = \"cifar10\") # Indicate dataset here\n",
    "\n",
    "# Load models for FAT and FedAvg\n",
    "save_path_FAT = 'path_to_trained_FAT_weights'\n",
    "save_path_FedAvg = 'path_to_trained_Fedavg_weights'\n",
    "\n",
    "model_FAT = copy.deepcopy(import_model_weights(num_user, setting, save_path_FAT, aggregator, args_)[0])\n",
    "model_Fedavg = import_model_weights(num_user, setting, save_path_FedAvg, aggregator, args_)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain parameters for each layer\n",
    "params_FAT = model_FAT.state_dict()\n",
    "params_FedAvg = model_Fedavg.state_dict()\n",
    "\n",
    "# Just take the values of weights and bias for the model\n",
    "desired_keys = [key for key in params_FAT.keys() if 'weight' in key or 'bias' in key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_global = model_FAT \n",
    "keys = desired_keys\n",
    "\n",
    "\n",
    "global_state_dict = model_global.state_dict(keep_vars=True)\n",
    "return_state_dict = copy.deepcopy(global_state_dict)\n",
    "\n",
    "for key in keys:\n",
    "    max_temp =  torch.max(global_state_dict[key].data)\n",
    "    min_temp = torch.min(global_state_dict[key].data)\n",
    "    global_shape = global_state_dict[key].shape\n",
    "    return_state_dict[key].data = (max_temp-min_temp)* torch.rand(global_shape).to('cuda') + min_temp \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate uploaded model and download to attacker clients in aggregator\n",
    "# Current version working under the assumption of close to convergence (no benign client pushback)\n",
    "def calc_noise_atk_model(model_global, keys, weight_scale_2 =1):\n",
    "\n",
    "    model_global = model_FAT \n",
    "    keys = desired_keys\n",
    "\n",
    "    atk_model = copy.deepcopy(model_global)\n",
    "    global_state_dict = model_global.state_dict(keep_vars=True)\n",
    "    return_state_dict = atk_model.state_dict(keep_vars=True)\n",
    "\n",
    "    for key in keys:\n",
    "        max_temp =  torch.max(global_state_dict[key].data)\n",
    "        min_temp = torch.min(global_state_dict[key].data)\n",
    "        global_shape = global_state_dict[key].shape\n",
    "        return_state_dict[key].data = weight_scale_2 * ((max_temp-min_temp)* torch.rand(global_shape).to('cuda') + min_temp)\n",
    "\n",
    "    return atk_model\n",
    "\n",
    "def manipulate_client_data():\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# THIS FUNCTION IS KEY IN PERFORMING OTHER TYPES OF ATTACKS\n",
    "# Expand aggregator.mix() function\n",
    "def UNL_mix_otheratk(aggregator, adv_id, keys, atk_type, weight_scale_2 = 1, dump_flag=False, aggregation_op = None, tm_beta = 0.05, class_count = 10):\n",
    "    # weight_scale = 1/aggregator.clients_weights\n",
    "    model_global = aggregator.global_learners_ensemble[0].model\n",
    "\n",
    "    if aggregation_op == None:\n",
    "        aggregation_op = aggregator.aggregation_op\n",
    "\n",
    "    # Give adversarial clients boosted models and train regular clients 1 round\n",
    "    benign_id = list(range(len(aggregator.clients)))\n",
    "\n",
    "    if atk_type == \"label_flip\":\n",
    "        for a_id in adv_id:\n",
    "            # Must change class-count for other data sets\n",
    "            aggregator.clients[a_id].swap_dataset_labels(class_count = class_count, switch_pair=False)\n",
    "    elif atk_type == \"noise\":\n",
    "        for a_id in adv_id:\n",
    "            benign_id.remove(a_id)\n",
    "            temp_atk_model = calc_noise_atk_model(model_global, keys, weight_scale_2)\n",
    "            aggregator.clients[a_id].learners_ensemble[0].model = copy.deepcopy(temp_atk_model)\n",
    "    else: \n",
    "        raise ValueError('Poison Attack not properly chosen [label_flip, noise]') \n",
    "\n",
    "    \n",
    "\n",
    "    for c_id in benign_id:\n",
    "        aggregator.clients[c_id].step()\n",
    "\n",
    "    # Aggregate model and download\n",
    "    for learner_id, learner in enumerate(aggregator.global_learners_ensemble):\n",
    "        learners = [client.learners_ensemble[learner_id] for client in aggregator.clients]\n",
    "        if aggregation_op is None:\n",
    "            average_learners(learners, learner, weights=aggregator.clients_weights)\n",
    "        elif aggregation_op == 'median':\n",
    "            dump_path = (\n",
    "                os.path.join(aggregator.dump_path, f\"round{aggregator.c_round}_median.pkl\") \n",
    "                if dump_flag\n",
    "                else None\n",
    "            )\n",
    "            byzantine_robust_aggregate_median(\n",
    "                learners, \n",
    "                learner, \n",
    "                dump_path=dump_path\n",
    "            )\n",
    "        elif aggregation_op == 'trimmed_mean':\n",
    "            dump_path = (\n",
    "                os.path.join(aggregator.dump_path, f\"round{aggregator.c_round}_tm.pkl\")\n",
    "                if dump_flag\n",
    "                else None\n",
    "            )\n",
    "            byzantine_robust_aggregate_tm(\n",
    "                learners, \n",
    "                learner, \n",
    "                beta=tm_beta, \n",
    "                dump_path=dump_path\n",
    "            )\n",
    "        elif aggregation_op == 'krum':\n",
    "            dump_path = (\n",
    "                os.path.join(aggregator.dump_path, f\"round{aggregator.c_round}_krum.pkl\")\n",
    "                if dump_flag\n",
    "                else None\n",
    "            )\n",
    "            byzantine_robust_aggregate_krum(\n",
    "                learners, \n",
    "                learner, \n",
    "                dump_path=dump_path\n",
    "            )\n",
    "        elif aggregation_op == 'krum_modelwise':\n",
    "            dump_path = (\n",
    "                os.path.join(aggregator.dump_path, f\"round{aggregator.c_round}_krum_modelwise.pkl\")\n",
    "                if dump_flag\n",
    "                else None\n",
    "            )\n",
    "            byzantine_robust_aggregate_krum_modelwise(\n",
    "                1,\n",
    "                learners,\n",
    "                learner,\n",
    "                dump_path=dump_path\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "    # assign the updated model to all clients\n",
    "    aggregator.update_clients()\n",
    "\n",
    "    aggregator.c_round += 1\n",
    "\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 223.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:32<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Test Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating adv data set\n",
      "Test acc:  0.7934375122189522 adv acc:  0.3406250044703484\n",
      "round 0 Test acc:  0.7990625113248825 adv acc:  0.31656250581145284\n",
      "round 1 Test acc:  0.7968750149011612 adv acc:  0.28968750573694707\n",
      "round 2 Test acc:  0.7900000125169754 adv acc:  0.27062500491738317\n",
      "round 3 Test acc:  0.7959375157952309 adv acc:  0.257812506519258\n",
      "round 4 Test acc:  0.8003125131130219 adv acc:  0.24187500290572644\n",
      "round 5 Test acc:  0.8075000137090683 adv acc:  0.24125000573694705\n",
      "round 6 Test acc:  0.8068750113248825 adv acc:  0.24000000655651094\n",
      "round 7 Test acc:  0.8040625095367432 adv acc:  0.2315625024959445\n",
      "round 8 Test acc:  0.7934375137090683 adv acc:  0.2346875049173832\n",
      "round 9 Test acc:  0.8025000154972076 adv acc:  0.22781250327825547\n",
      "round 10 Test acc:  0.8025000140070915 adv acc:  0.23187500461935998\n",
      "round 11 Test acc:  0.7950000122189522 adv acc:  0.2203125063329935\n",
      "round 12 Test acc:  0.7978125080466271 adv acc:  0.2278125047683716\n",
      "round 13 Test acc:  0.7990625113248825 adv acc:  0.2290625035762787\n",
      "round 14 Test acc:  0.7890625119209289 adv acc:  0.2234375039115548\n",
      "round 15 Test acc:  0.7928125113248825 adv acc:  0.23156250473111867\n",
      "round 16 Test acc:  0.7968750089406967 adv acc:  0.22406250424683094\n",
      "round 17 Test acc:  0.795312511920929 adv acc:  0.22625000439584256\n",
      "round 18 Test acc:  0.7906250119209289 adv acc:  0.22031250447034836\n",
      "round 19 Test acc:  0.7887500137090683 adv acc:  0.22125000469386577\n",
      "updating adv data set\n",
      "Test acc:  0.8065625086426735 adv acc:  0.3578125059604645\n",
      "round 0 Test acc:  0.7909375101327896 adv acc:  0.3421875059604645\n",
      "round 1 Test acc:  0.7703125134110451 adv acc:  0.3384375058114529\n",
      "round 2 Test acc:  0.7478125110268593 adv acc:  0.30031250454485414\n",
      "round 3 Test acc:  0.7137500137090683 adv acc:  0.278750005364418\n",
      "round 4 Test acc:  0.6993750110268593 adv acc:  0.27687500678002835\n",
      "round 5 Test acc:  0.6828125104308128 adv acc:  0.27187500409781934\n",
      "round 6 Test acc:  0.6915625154972076 adv acc:  0.27968750409781934\n",
      "round 7 Test acc:  0.6803125128149986 adv acc:  0.25875000543892385\n",
      "round 8 Test acc:  0.6550000138580799 adv acc:  0.25437500458210704\n",
      "round 9 Test acc:  0.6568750120699406 adv acc:  0.25125000439584255\n",
      "round 10 Test acc:  0.6634375110268593 adv acc:  0.24500000458210708\n",
      "round 11 Test acc:  0.6209375113248825 adv acc:  0.23187500480562448\n",
      "round 12 Test acc:  0.6468750104308129 adv acc:  0.23468750342726707\n",
      "round 13 Test acc:  0.6178125083446503 adv acc:  0.22656250596046448\n",
      "round 14 Test acc:  0.6084375113248826 adv acc:  0.2165625046938658\n",
      "round 15 Test acc:  0.6115625128149986 adv acc:  0.22281250413507223\n",
      "round 16 Test acc:  0.5915625110268593 adv acc:  0.20812500286847352\n",
      "round 17 Test acc:  0.579375010728836 adv acc:  0.19406250305473804\n",
      "round 18 Test acc:  0.5493750110268593 adv acc:  0.18312500286847352\n",
      "round 19 Test acc:  0.5409375078976154 adv acc:  0.1821875035762787\n"
     ]
    }
   ],
   "source": [
    "beta_params = [0.2,0.2]\n",
    "agg_op_list = [\"trimmed_mean\", \"trimmed_mean\"]\n",
    "num_aru = [10,10]\n",
    "weight2_list = [1,1]\n",
    "atype = ['label_flip', 'noise']\n",
    "\n",
    "Fu_count = [15,15,15]\n",
    "G_count = [0.7,0.7,0.7]\n",
    "\n",
    "num_rounds = 20\n",
    "num_class = 10 # cifar 10\n",
    "\n",
    "result_list = []\n",
    "for itt in range(len(beta_params)):\n",
    "    result_list += [{}]\n",
    "\n",
    "setting, num_user = \"FedAvg_adv\", 40\n",
    "save_path_FedAvg_150R = 'weights/cifar10/231031_FAT150round/FAT'\n",
    "aggregator, clients, args_ = set_args(setting, num_user)\n",
    "\n",
    "\n",
    "\n",
    "for itt in range(len(beta_params)):\n",
    "    print(\"updating adv data set\")\n",
    "    Fu = np.zeros(num_user)\n",
    "    Fu[0:Fu_count[itt]] = 1 * G_count[itt]\n",
    "\n",
    "    aggregator.aggregation_op = agg_op_list[itt]\n",
    "\n",
    "    # Setting evasion attack parameters\n",
    "    x_min = torch.min(clients[0].adv_nn.dataloader.x_data)\n",
    "    x_max = torch.max(clients[0].adv_nn.dataloader.x_data)\n",
    "    atk_params = PGD_Params()\n",
    "    atk_params.set_params(batch_size=1, iteration = 10,\n",
    "                    target = -1, x_val_min = x_min, x_val_max = x_max,\n",
    "                    step_size = 0.05, step_norm = \"inf\", eps = 4.5, eps_norm = 2)\n",
    "\n",
    "    # Assign proportion and attack params\n",
    "    for c in range(len(clients)):\n",
    "        if Fu[c] > 0:\n",
    "            aggregator.clients[c].set_adv_params(Fu[c], atk_params)\n",
    "            aggregator.clients[c].update_advnn()\n",
    "            aggregator.clients[c].assign_advdataset()\n",
    "\n",
    "    # Perform 50 rounds of FAT on FedAvg model \n",
    "    num_adv = num_aru[itt]\n",
    "    weight2 = weight2_list[itt]\n",
    "    adv_id = random.sample(range(Fu_count[itt],num_user), num_adv) # excluding 0-9 as Fu = 1\n",
    "    beta = beta_params[itt]\n",
    "\n",
    "    test_acc_gather = []\n",
    "    adv_acc_gather = []\n",
    "    test_acc_std = []\n",
    "    adv_acc_std = []\n",
    "\n",
    "    aggregator.tm_rate = beta\n",
    "\n",
    "    # Test performance of aggregator on data \n",
    "    aggregator.load_state(dir_path = save_path_FedAvg_150R)\n",
    "    aggregator.update_clients()\n",
    "    model_FA = pull_model_from_agg(aggregator)\n",
    "    model_FA.eval()\n",
    "    acc, adv_acc = get_adv_acc(aggregator, model_FA)\n",
    "\n",
    "    prev_model = copy.deepcopy(model_FA)\n",
    "\n",
    "    print(\"Test acc: \", np.mean(acc), \"adv acc: \", np.mean(adv_acc))\n",
    "    test_acc_gather+= [np.mean(acc)]\n",
    "    adv_acc_gather += [np.mean(adv_acc)]\n",
    "    test_acc_std += [np.std(acc)]\n",
    "    adv_acc_std += [np.std(adv_acc)]\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(num_rounds):\n",
    "\n",
    "        # Per round Freq\n",
    "\n",
    "        # aggregator.mix()\n",
    "        UNL_mix_otheratk(aggregator, adv_id, keys = desired_keys, atk_type = atype[itt], weight_scale_2 = weight2, dump_flag=False, tm_beta=beta, class_count = num_class)\n",
    "        model_overfit = pull_model_from_agg(aggregator)\n",
    "        model_overfit.eval()\n",
    "        acc, adv_acc = get_adv_acc(aggregator, model_overfit)\n",
    "\n",
    "        print(\"round\", i,\"Test acc: \", np.mean(acc), \"adv acc: \", np.mean(adv_acc))\n",
    "        test_acc_gather+= [np.mean(acc)]\n",
    "        adv_acc_gather += [np.mean(adv_acc)]\n",
    "        test_acc_std += [np.std(acc)]\n",
    "        adv_acc_std += [np.std(adv_acc)]\n",
    "        prev_model = copy.deepcopy(model_overfit)\n",
    "\n",
    "        result_list[itt]['test_acc'] = copy.deepcopy(test_acc_gather)\n",
    "        result_list[itt]['adv_acc'] = copy.deepcopy(adv_acc_gather)\n",
    "        result_list[itt]['test_std'] = copy.deepcopy(test_acc_std)\n",
    "        result_list[itt]['adv_std'] = copy.deepcopy(adv_acc_std)\n",
    "        result_list[itt]['num_clients'] = num_adv\n",
    "        result_list[itt]['beta'] = beta\n",
    "        result_list[itt]['poison_type'] = atype[itt]\n",
    "        # Perform gradient direction gathering\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "a = result_list\n",
    "\n",
    "with open('saved_results/poison_sweep/240201_02_vanilla_yestm.pk', 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedEM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
