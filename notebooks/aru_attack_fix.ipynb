{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fedatk_unl_tj\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/fedatk_unl_tj/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/FedEM_env/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/ubuntu/anaconda3/envs/FedEM_env/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Import General Libraries\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# Import FedEM based Libraries\n",
    "from utils.utils import *\n",
    "from utils.constants import *\n",
    "from utils.args import *\n",
    "from utils.util_notebooks import *\n",
    "from run_experiment import *\n",
    "from models import *\n",
    "\n",
    "# Import Transfer Attack\n",
    "from transfer_attacks.Personalized_NN import *\n",
    "from transfer_attacks.Params import *\n",
    "from transfer_attacks.Transferer import *\n",
    "from transfer_attacks.Args import *\n",
    "from transfer_attacks.TA_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 39/80 [00:00<00:00, 118.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]/home/ubuntu/anaconda3/envs/FedEM_env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/FedEM_env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 40/40 [00:16<00:00,  2.37it/s]\n",
      "/home/ubuntu/fedatk_unl_tj/aggregator.py:289: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  learner.model.load_state_dict(torch.load(chkpts_path))\n"
     ]
    }
   ],
   "source": [
    "setting, num_user = \"FedAvg_adv\", 40\n",
    "exp = \"cifar10\"\n",
    "\n",
    "try: # Skip loading if already loaded\n",
    "    aggregator\n",
    "except:\n",
    "    aggregator, clients, args_ = set_args(setting, num_user,  experiment = exp) # Indicate dataset here\n",
    "\n",
    "# Load models for FAT and FedAvg\n",
    "save_path_FAT = '/home/ubuntu/fedatk_unl_tj/weights/cifar10/231031_FAT150round/FAT/'\n",
    "save_path_FedAvg =  '/home/ubuntu/fedatk_unl_tj/weights/cifar10/230922_baseline_train/fedavg/'\n",
    "\n",
    "model_FAT = copy.deepcopy(import_model_weights(num_user, setting, save_path_FAT, aggregator, args_)[0])\n",
    "model_Fedavg = import_model_weights(num_user, setting, save_path_FedAvg, aggregator, args_)[0]\n",
    "\n",
    "# del aggregator, clients, args_\n",
    "# torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain parameters for each layer\n",
    "params_FAT = model_FAT.state_dict()\n",
    "params_FedAvg = model_Fedavg.state_dict()\n",
    "\n",
    "# Just take the values of weights and bias for the model\n",
    "desired_keys = [key for key in params_FAT.keys() if 'weight' in key or 'bias' in key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_aru = 1\n",
    "num_rounds = 1\n",
    "eps_train = 4.5\n",
    "eps_attack = 4\n",
    "weight_2 = 1\n",
    "step_size = 0.01\n",
    "steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform rounds of FAT on FedAvg model\n",
    "aggregator.load_state(dir_path=save_path_FAT)\n",
    "aggregator.update_clients()\n",
    "aggregator.op = None\n",
    "weight_scale_2 = 1\n",
    "\n",
    "# UNL_mix(aggregator, adv_id=[0], model_inject=model_Fedavg, weight_scale_2 = weight_scale_2, keys=desired_keys, aggregation_op = None)\n",
    "\n",
    "# model_overfit = pull_model_from_agg(aggregator)\n",
    "# model_overfit.eval()\n",
    "# acc, adv_acc = get_adv_acc(aggregator, model_overfit, eps=eps_attack, step_size = step_size, steps = steps)\n",
    "# print(\"Test acc: \", np.mean(acc), \" (\", np.std(acc),\") \", \"adv acc: \", np.mean(adv_acc),\" (\", np.std(adv_acc),\") \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.0.weight total\n",
      "features.0.1.weight total\n",
      "features.0.1.bias total\n",
      "features.0.1.running_mean total\n",
      "features.0.1.running_var total\n",
      "features.0.1.num_batches_tracked total\n",
      "features.1.conv.0.0.weight total\n",
      "features.1.conv.0.1.weight total\n",
      "features.1.conv.0.1.bias total\n",
      "features.1.conv.0.1.running_mean total\n",
      "features.1.conv.0.1.running_var total\n",
      "features.1.conv.0.1.num_batches_tracked total\n",
      "features.1.conv.1.weight total\n",
      "features.1.conv.2.weight total\n",
      "features.1.conv.2.bias total\n",
      "features.1.conv.2.running_mean total\n",
      "features.1.conv.2.running_var total\n",
      "features.1.conv.2.num_batches_tracked total\n",
      "features.2.conv.0.0.weight total\n",
      "features.2.conv.0.1.weight total\n",
      "features.2.conv.0.1.bias total\n",
      "features.2.conv.0.1.running_mean total\n",
      "features.2.conv.0.1.running_var total\n",
      "features.2.conv.0.1.num_batches_tracked total\n",
      "features.2.conv.1.0.weight total\n",
      "features.2.conv.1.1.weight total\n",
      "features.2.conv.1.1.bias total\n",
      "features.2.conv.1.1.running_mean total\n",
      "features.2.conv.1.1.running_var total\n",
      "features.2.conv.1.1.num_batches_tracked total\n",
      "features.2.conv.2.weight total\n",
      "features.2.conv.3.weight total\n",
      "features.2.conv.3.bias total\n",
      "features.2.conv.3.running_mean total\n",
      "features.2.conv.3.running_var total\n",
      "features.2.conv.3.num_batches_tracked total\n",
      "features.3.conv.0.0.weight total\n",
      "features.3.conv.0.1.weight total\n",
      "features.3.conv.0.1.bias total\n",
      "features.3.conv.0.1.running_mean total\n",
      "features.3.conv.0.1.running_var total\n",
      "features.3.conv.0.1.num_batches_tracked total\n",
      "features.3.conv.1.0.weight total\n",
      "features.3.conv.1.1.weight total\n",
      "features.3.conv.1.1.bias total\n",
      "features.3.conv.1.1.running_mean total\n",
      "features.3.conv.1.1.running_var total\n",
      "features.3.conv.1.1.num_batches_tracked total\n",
      "features.3.conv.2.weight total\n",
      "features.3.conv.3.weight total\n",
      "features.3.conv.3.bias total\n",
      "features.3.conv.3.running_mean total\n",
      "features.3.conv.3.running_var total\n",
      "features.3.conv.3.num_batches_tracked total\n",
      "features.4.conv.0.0.weight total\n",
      "features.4.conv.0.1.weight total\n",
      "features.4.conv.0.1.bias total\n",
      "features.4.conv.0.1.running_mean total\n",
      "features.4.conv.0.1.running_var total\n",
      "features.4.conv.0.1.num_batches_tracked total\n",
      "features.4.conv.1.0.weight total\n",
      "features.4.conv.1.1.weight total\n",
      "features.4.conv.1.1.bias total\n",
      "features.4.conv.1.1.running_mean total\n",
      "features.4.conv.1.1.running_var total\n",
      "features.4.conv.1.1.num_batches_tracked total\n",
      "features.4.conv.2.weight total\n",
      "features.4.conv.3.weight total\n",
      "features.4.conv.3.bias total\n",
      "features.4.conv.3.running_mean total\n",
      "features.4.conv.3.running_var total\n",
      "features.4.conv.3.num_batches_tracked total\n",
      "features.5.conv.0.0.weight total\n",
      "features.5.conv.0.1.weight total\n",
      "features.5.conv.0.1.bias total\n",
      "features.5.conv.0.1.running_mean total\n",
      "features.5.conv.0.1.running_var total\n",
      "features.5.conv.0.1.num_batches_tracked total\n",
      "features.5.conv.1.0.weight total\n",
      "features.5.conv.1.1.weight total\n",
      "features.5.conv.1.1.bias total\n",
      "features.5.conv.1.1.running_mean total\n",
      "features.5.conv.1.1.running_var total\n",
      "features.5.conv.1.1.num_batches_tracked total\n",
      "features.5.conv.2.weight total\n",
      "features.5.conv.3.weight total\n",
      "features.5.conv.3.bias total\n",
      "features.5.conv.3.running_mean total\n",
      "features.5.conv.3.running_var total\n",
      "features.5.conv.3.num_batches_tracked total\n",
      "features.6.conv.0.0.weight total\n",
      "features.6.conv.0.1.weight total\n",
      "features.6.conv.0.1.bias total\n",
      "features.6.conv.0.1.running_mean total\n",
      "features.6.conv.0.1.running_var total\n",
      "features.6.conv.0.1.num_batches_tracked total\n",
      "features.6.conv.1.0.weight total\n",
      "features.6.conv.1.1.weight total\n",
      "features.6.conv.1.1.bias total\n",
      "features.6.conv.1.1.running_mean total\n",
      "features.6.conv.1.1.running_var total\n",
      "features.6.conv.1.1.num_batches_tracked total\n",
      "features.6.conv.2.weight total\n",
      "features.6.conv.3.weight total\n",
      "features.6.conv.3.bias total\n",
      "features.6.conv.3.running_mean total\n",
      "features.6.conv.3.running_var total\n",
      "features.6.conv.3.num_batches_tracked total\n",
      "features.7.conv.0.0.weight total\n",
      "features.7.conv.0.1.weight total\n",
      "features.7.conv.0.1.bias total\n",
      "features.7.conv.0.1.running_mean total\n",
      "features.7.conv.0.1.running_var total\n",
      "features.7.conv.0.1.num_batches_tracked total\n",
      "features.7.conv.1.0.weight total\n",
      "features.7.conv.1.1.weight total\n",
      "features.7.conv.1.1.bias total\n",
      "features.7.conv.1.1.running_mean total\n",
      "features.7.conv.1.1.running_var total\n",
      "features.7.conv.1.1.num_batches_tracked total\n",
      "features.7.conv.2.weight total\n",
      "features.7.conv.3.weight total\n",
      "features.7.conv.3.bias total\n",
      "features.7.conv.3.running_mean total\n",
      "features.7.conv.3.running_var total\n",
      "features.7.conv.3.num_batches_tracked total\n",
      "features.8.conv.0.0.weight total\n",
      "features.8.conv.0.1.weight total\n",
      "features.8.conv.0.1.bias total\n",
      "features.8.conv.0.1.running_mean total\n",
      "features.8.conv.0.1.running_var total\n",
      "features.8.conv.0.1.num_batches_tracked total\n",
      "features.8.conv.1.0.weight total\n",
      "features.8.conv.1.1.weight total\n",
      "features.8.conv.1.1.bias total\n",
      "features.8.conv.1.1.running_mean total\n",
      "features.8.conv.1.1.running_var total\n",
      "features.8.conv.1.1.num_batches_tracked total\n",
      "features.8.conv.2.weight total\n",
      "features.8.conv.3.weight total\n",
      "features.8.conv.3.bias total\n",
      "features.8.conv.3.running_mean total\n",
      "features.8.conv.3.running_var total\n",
      "features.8.conv.3.num_batches_tracked total\n",
      "features.9.conv.0.0.weight total\n",
      "features.9.conv.0.1.weight total\n",
      "features.9.conv.0.1.bias total\n",
      "features.9.conv.0.1.running_mean total\n",
      "features.9.conv.0.1.running_var total\n",
      "features.9.conv.0.1.num_batches_tracked total\n",
      "features.9.conv.1.0.weight total\n",
      "features.9.conv.1.1.weight total\n",
      "features.9.conv.1.1.bias total\n",
      "features.9.conv.1.1.running_mean total\n",
      "features.9.conv.1.1.running_var total\n",
      "features.9.conv.1.1.num_batches_tracked total\n",
      "features.9.conv.2.weight total\n",
      "features.9.conv.3.weight total\n",
      "features.9.conv.3.bias total\n",
      "features.9.conv.3.running_mean total\n",
      "features.9.conv.3.running_var total\n",
      "features.9.conv.3.num_batches_tracked total\n",
      "features.10.conv.0.0.weight total\n",
      "features.10.conv.0.1.weight total\n",
      "features.10.conv.0.1.bias total\n",
      "features.10.conv.0.1.running_mean total\n",
      "features.10.conv.0.1.running_var total\n",
      "features.10.conv.0.1.num_batches_tracked total\n",
      "features.10.conv.1.0.weight total\n",
      "features.10.conv.1.1.weight total\n",
      "features.10.conv.1.1.bias total\n",
      "features.10.conv.1.1.running_mean total\n",
      "features.10.conv.1.1.running_var total\n",
      "features.10.conv.1.1.num_batches_tracked total\n",
      "features.10.conv.2.weight total\n",
      "features.10.conv.3.weight total\n",
      "features.10.conv.3.bias total\n",
      "features.10.conv.3.running_mean total\n",
      "features.10.conv.3.running_var total\n",
      "features.10.conv.3.num_batches_tracked total\n",
      "features.11.conv.0.0.weight total\n",
      "features.11.conv.0.1.weight total\n",
      "features.11.conv.0.1.bias total\n",
      "features.11.conv.0.1.running_mean total\n",
      "features.11.conv.0.1.running_var total\n",
      "features.11.conv.0.1.num_batches_tracked total\n",
      "features.11.conv.1.0.weight total\n",
      "features.11.conv.1.1.weight total\n",
      "features.11.conv.1.1.bias total\n",
      "features.11.conv.1.1.running_mean total\n",
      "features.11.conv.1.1.running_var total\n",
      "features.11.conv.1.1.num_batches_tracked total\n",
      "features.11.conv.2.weight total\n",
      "features.11.conv.3.weight total\n",
      "features.11.conv.3.bias total\n",
      "features.11.conv.3.running_mean total\n",
      "features.11.conv.3.running_var total\n",
      "features.11.conv.3.num_batches_tracked total\n",
      "features.12.conv.0.0.weight total\n",
      "features.12.conv.0.1.weight total\n",
      "features.12.conv.0.1.bias total\n",
      "features.12.conv.0.1.running_mean total\n",
      "features.12.conv.0.1.running_var total\n",
      "features.12.conv.0.1.num_batches_tracked total\n",
      "features.12.conv.1.0.weight total\n",
      "features.12.conv.1.1.weight total\n",
      "features.12.conv.1.1.bias total\n",
      "features.12.conv.1.1.running_mean total\n",
      "features.12.conv.1.1.running_var total\n",
      "features.12.conv.1.1.num_batches_tracked total\n",
      "features.12.conv.2.weight total\n",
      "features.12.conv.3.weight total\n",
      "features.12.conv.3.bias total\n",
      "features.12.conv.3.running_mean total\n",
      "features.12.conv.3.running_var total\n",
      "features.12.conv.3.num_batches_tracked total\n",
      "features.13.conv.0.0.weight total\n",
      "features.13.conv.0.1.weight total\n",
      "features.13.conv.0.1.bias total\n",
      "features.13.conv.0.1.running_mean total\n",
      "features.13.conv.0.1.running_var total\n",
      "features.13.conv.0.1.num_batches_tracked total\n",
      "features.13.conv.1.0.weight total\n",
      "features.13.conv.1.1.weight total\n",
      "features.13.conv.1.1.bias total\n",
      "features.13.conv.1.1.running_mean total\n",
      "features.13.conv.1.1.running_var total\n",
      "features.13.conv.1.1.num_batches_tracked total\n",
      "features.13.conv.2.weight total\n",
      "features.13.conv.3.weight total\n",
      "features.13.conv.3.bias total\n",
      "features.13.conv.3.running_mean total\n",
      "features.13.conv.3.running_var total\n",
      "features.13.conv.3.num_batches_tracked total\n",
      "features.14.conv.0.0.weight total\n",
      "features.14.conv.0.1.weight total\n",
      "features.14.conv.0.1.bias total\n",
      "features.14.conv.0.1.running_mean total\n",
      "features.14.conv.0.1.running_var total\n",
      "features.14.conv.0.1.num_batches_tracked total\n",
      "features.14.conv.1.0.weight total\n",
      "features.14.conv.1.1.weight total\n",
      "features.14.conv.1.1.bias total\n",
      "features.14.conv.1.1.running_mean total\n",
      "features.14.conv.1.1.running_var total\n",
      "features.14.conv.1.1.num_batches_tracked total\n",
      "features.14.conv.2.weight total\n",
      "features.14.conv.3.weight total\n",
      "features.14.conv.3.bias total\n",
      "features.14.conv.3.running_mean total\n",
      "features.14.conv.3.running_var total\n",
      "features.14.conv.3.num_batches_tracked total\n",
      "features.15.conv.0.0.weight total\n",
      "features.15.conv.0.1.weight total\n",
      "features.15.conv.0.1.bias total\n",
      "features.15.conv.0.1.running_mean total\n",
      "features.15.conv.0.1.running_var total\n",
      "features.15.conv.0.1.num_batches_tracked total\n",
      "features.15.conv.1.0.weight total\n",
      "features.15.conv.1.1.weight total\n",
      "features.15.conv.1.1.bias total\n",
      "features.15.conv.1.1.running_mean total\n",
      "features.15.conv.1.1.running_var total\n",
      "features.15.conv.1.1.num_batches_tracked total\n",
      "features.15.conv.2.weight total\n",
      "features.15.conv.3.weight total\n",
      "features.15.conv.3.bias total\n",
      "features.15.conv.3.running_mean total\n",
      "features.15.conv.3.running_var total\n",
      "features.15.conv.3.num_batches_tracked total\n",
      "features.16.conv.0.0.weight total\n",
      "features.16.conv.0.1.weight total\n",
      "features.16.conv.0.1.bias total\n",
      "features.16.conv.0.1.running_mean total\n",
      "features.16.conv.0.1.running_var total\n",
      "features.16.conv.0.1.num_batches_tracked total\n",
      "features.16.conv.1.0.weight total\n",
      "features.16.conv.1.1.weight total\n",
      "features.16.conv.1.1.bias total\n",
      "features.16.conv.1.1.running_mean total\n",
      "features.16.conv.1.1.running_var total\n",
      "features.16.conv.1.1.num_batches_tracked total\n",
      "features.16.conv.2.weight total\n",
      "features.16.conv.3.weight total\n",
      "features.16.conv.3.bias total\n",
      "features.16.conv.3.running_mean total\n",
      "features.16.conv.3.running_var total\n",
      "features.16.conv.3.num_batches_tracked total\n",
      "features.17.conv.0.0.weight total\n",
      "features.17.conv.0.1.weight total\n",
      "features.17.conv.0.1.bias total\n",
      "features.17.conv.0.1.running_mean total\n",
      "features.17.conv.0.1.running_var total\n",
      "features.17.conv.0.1.num_batches_tracked total\n",
      "features.17.conv.1.0.weight total\n",
      "features.17.conv.1.1.weight total\n",
      "features.17.conv.1.1.bias total\n",
      "features.17.conv.1.1.running_mean total\n",
      "features.17.conv.1.1.running_var total\n",
      "features.17.conv.1.1.num_batches_tracked total\n",
      "features.17.conv.2.weight total\n",
      "features.17.conv.3.weight total\n",
      "features.17.conv.3.bias total\n",
      "features.17.conv.3.running_mean total\n",
      "features.17.conv.3.running_var total\n",
      "features.17.conv.3.num_batches_tracked total\n",
      "features.18.0.weight total\n",
      "features.18.1.weight total\n",
      "features.18.1.bias total\n",
      "features.18.1.running_mean total\n",
      "features.18.1.running_var total\n",
      "features.18.1.num_batches_tracked total\n",
      "classifier.1.weight total\n",
      "classifier.1.bias total\n"
     ]
    }
   ],
   "source": [
    "# def calc_atk_model_debug(model_inject, model_global, keys, weight_scale, weight_scale_2):\n",
    "#     with torch.no_grad():\n",
    "#         atk_model = copy.deepcopy(model_global)\n",
    "#         inject_state_dict = model_inject.state_dict(keep_vars=False)\n",
    "#         global_state_dict = model_global.state_dict(keep_vars=False)\n",
    "#         return_state_dict = atk_model.state_dict(keep_vars=False)\n",
    "#         total_weight = weight_scale * weight_scale_2\n",
    "\n",
    "#         for key in keys:\n",
    "#             diff = inject_state_dict[key].data.clone() - global_state_dict[key].data.clone()\n",
    "#             return_state_dict[key].data = total_weight * diff + global_state_dict[key].data.clone()\n",
    "\n",
    "#         atk_model.load_state_dict(return_state_dict)\n",
    "#         return atk_model\n",
    "\n",
    "def calc_atk_model_debug(model_inject, model_global, keys, weight_scale, weight_scale_2):\n",
    "\n",
    "    atk_model = copy.deepcopy(model_inject)\n",
    "    inject_state_dict = model_inject.state_dict(keep_vars=False)\n",
    "    global_state_dict = model_global.state_dict(keep_vars=False)\n",
    "    return_state_dict = atk_model.state_dict(keep_vars=False)\n",
    "    total_weight = weight_scale * weight_scale_2\n",
    "\n",
    "    # for key in keys:\n",
    "    for key in inject_state_dict.keys():\n",
    "        print(key, \"total\")\n",
    "        diff = inject_state_dict[key].data.clone() - global_state_dict[key].data.clone()\n",
    "        return_state_dict[key].data = total_weight * diff + global_state_dict[key].data.clone()\n",
    "\n",
    "    atk_model.load_state_dict(return_state_dict)\n",
    "\n",
    "    return atk_model\n",
    "\n",
    "def average_learners_inject(\n",
    "        learners,\n",
    "        target_learner,\n",
    "        weights=None,\n",
    "        average_params=True,\n",
    "        average_gradients=False, \n",
    "        desired_keys = None\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Compute the average of a list of learners_ensemble and store it into learner\n",
    "\n",
    "    :param learners:\n",
    "    :type learners: List[Learner]\n",
    "    :param target_learner:\n",
    "    :type target_learner: Learner\n",
    "    :param weights: tensor of the same size as learners_ensemble, having values between 0 and 1, and summing to 1,\n",
    "                    if None, uniform learners_weights are used\n",
    "    :param average_params: if set to true the parameters are averaged; default is True\n",
    "    :param average_gradients: if set to true the gradient are also averaged; default is False\n",
    "    :type weights: torch.Tensor\n",
    "\n",
    "    \"\"\"\n",
    "    if not average_params and not average_gradients:\n",
    "        return\n",
    "\n",
    "    if weights is None:\n",
    "        n_learners = len(learners)\n",
    "        weights = (1 / n_learners) * torch.ones(n_learners, device=learners[0].device)\n",
    "\n",
    "    else:\n",
    "        weights = weights.to(learners[0].device)\n",
    "\n",
    "    target_state_dict = target_learner.model.state_dict(keep_vars=True)\n",
    "    if desired_keys is None:\n",
    "        desired_keys = [key for key in target_state_dict.keys() if 'weight' in key or 'bias' in key]\n",
    "\n",
    "    for key in desired_keys:\n",
    "\n",
    "        if target_state_dict[key].data.dtype == torch.float32:\n",
    "\n",
    "            if average_params:\n",
    "                target_state_dict[key].data.fill_(0.)\n",
    "\n",
    "            if average_gradients:\n",
    "                target_state_dict[key].grad = target_state_dict[key].data.clone()\n",
    "                target_state_dict[key].grad.data.fill_(0.)\n",
    "\n",
    "            for learner_id, learner in enumerate(learners):\n",
    "                state_dict = learner.model.state_dict(keep_vars=True)\n",
    "\n",
    "                if average_params:\n",
    "                    target_state_dict[key].data += weights[learner_id] * state_dict[key].data.clone()\n",
    "\n",
    "                if average_gradients:\n",
    "                    if state_dict[key].grad is not None:\n",
    "                        target_state_dict[key].grad += weights[learner_id] * state_dict[key].grad.clone()\n",
    "                    elif state_dict[key].requires_grad:\n",
    "                        warnings.warn(\n",
    "                            \"trying to average_gradients before back propagation,\"\n",
    "                            \" you should set `average_gradients=False`.\"\n",
    "                        )\n",
    "\n",
    "        else:\n",
    "            # tracked batches\n",
    "            target_state_dict[key].data.fill_(0)\n",
    "            for learner_id, learner in enumerate(learners):\n",
    "                state_dict = learner.model.state_dict()\n",
    "                target_state_dict[key].data += state_dict[key].data.clone()\n",
    "\n",
    "\n",
    "aggregator.load_state(dir_path=save_path_FAT)\n",
    "aggregator.update_clients()\n",
    "aggregator.op = None\n",
    "\n",
    "adv_id = [0]\n",
    "weight_scale =  1/aggregator.clients_weights # np.ones(aggregator.clients_weights.shape)#\n",
    "model_global = aggregator.global_learners_ensemble[0].model\n",
    "model_inject = model_Fedavg\n",
    "aggregation_op = None\n",
    "keys = desired_keys\n",
    "\n",
    "# Based on aggregation methods change weight scale\n",
    "if aggregation_op in ['median', 'krum', 'median_sublayers']:# == \"median\" or aggregation_op == \"krum\":\n",
    "    weight_scale = np.ones(weight_scale.shape)\n",
    "\n",
    "# # Give adversarial clients boosted models and train regular clients 1 round\n",
    "benign_id = list(range(len(aggregator.clients)))\n",
    "\n",
    "for a_id in adv_id:\n",
    "    benign_id.remove(a_id)\n",
    "    temp_atk_model = calc_atk_model_debug(model_inject, model_global, keys, weight_scale[a_id], weight_scale_2)\n",
    "    # aggregator.clients[a_id].learners_ensemble[0].model.cpu()\n",
    "    # del aggregator.clients[a_id].learners_ensemble[0].model\n",
    "    # aggregator.clients[a_id].learners_ensemble[0].model = temp_atk_model\n",
    "    # # del temp_atk_model\n",
    "    # gc.collect()\n",
    "    # torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# for c_id in benign_id:\n",
    "#     aggregator.clients[c_id].step()\n",
    "\n",
    "# # Aggregate model and download\n",
    "# for learner_id, learner in enumerate(aggregator.global_learners_ensemble):\n",
    "#     learners = [client.learners_ensemble[learner_id] for client in aggregator.clients]\n",
    "#     if aggregation_op is None:\n",
    "#         average_learners_inject(learners, learner, weights=aggregator.clients_weights, desired_keys = desired_keys)\n",
    "#         print(\"averaging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.0.weight\n",
      "features.0.1.weight\n",
      "features.0.1.bias\n",
      "features.0.1.running_mean\n",
      "features.0.1.running_var\n",
      "features.0.1.num_batches_tracked\n",
      "features.1.conv.0.0.weight\n",
      "features.1.conv.0.1.weight\n",
      "features.1.conv.0.1.bias\n",
      "features.1.conv.0.1.running_mean\n",
      "features.1.conv.0.1.running_var\n",
      "features.1.conv.0.1.num_batches_tracked\n",
      "features.1.conv.1.weight\n",
      "features.1.conv.2.weight\n",
      "features.1.conv.2.bias\n",
      "features.1.conv.2.running_mean\n",
      "features.1.conv.2.running_var\n",
      "features.1.conv.2.num_batches_tracked\n",
      "features.2.conv.0.0.weight\n",
      "features.2.conv.0.1.weight\n",
      "features.2.conv.0.1.bias\n",
      "features.2.conv.0.1.running_mean\n",
      "features.2.conv.0.1.running_var\n",
      "features.2.conv.0.1.num_batches_tracked\n",
      "features.2.conv.1.0.weight\n",
      "features.2.conv.1.1.weight\n",
      "features.2.conv.1.1.bias\n",
      "features.2.conv.1.1.running_mean\n",
      "features.2.conv.1.1.running_var\n",
      "features.2.conv.1.1.num_batches_tracked\n",
      "features.2.conv.2.weight\n",
      "features.2.conv.3.weight\n",
      "features.2.conv.3.bias\n",
      "features.2.conv.3.running_mean\n",
      "features.2.conv.3.running_var\n",
      "features.2.conv.3.num_batches_tracked\n",
      "features.3.conv.0.0.weight\n",
      "features.3.conv.0.1.weight\n",
      "features.3.conv.0.1.bias\n",
      "features.3.conv.0.1.running_mean\n",
      "features.3.conv.0.1.running_var\n",
      "features.3.conv.0.1.num_batches_tracked\n",
      "features.3.conv.1.0.weight\n",
      "features.3.conv.1.1.weight\n",
      "features.3.conv.1.1.bias\n",
      "features.3.conv.1.1.running_mean\n",
      "features.3.conv.1.1.running_var\n",
      "features.3.conv.1.1.num_batches_tracked\n",
      "features.3.conv.2.weight\n",
      "features.3.conv.3.weight\n",
      "features.3.conv.3.bias\n",
      "features.3.conv.3.running_mean\n",
      "features.3.conv.3.running_var\n",
      "features.3.conv.3.num_batches_tracked\n",
      "features.4.conv.0.0.weight\n",
      "features.4.conv.0.1.weight\n",
      "features.4.conv.0.1.bias\n",
      "features.4.conv.0.1.running_mean\n",
      "features.4.conv.0.1.running_var\n",
      "features.4.conv.0.1.num_batches_tracked\n",
      "features.4.conv.1.0.weight\n",
      "features.4.conv.1.1.weight\n",
      "features.4.conv.1.1.bias\n",
      "features.4.conv.1.1.running_mean\n",
      "features.4.conv.1.1.running_var\n",
      "features.4.conv.1.1.num_batches_tracked\n",
      "features.4.conv.2.weight\n",
      "features.4.conv.3.weight\n",
      "features.4.conv.3.bias\n",
      "features.4.conv.3.running_mean\n",
      "features.4.conv.3.running_var\n",
      "features.4.conv.3.num_batches_tracked\n",
      "features.5.conv.0.0.weight\n",
      "features.5.conv.0.1.weight\n",
      "features.5.conv.0.1.bias\n",
      "features.5.conv.0.1.running_mean\n",
      "features.5.conv.0.1.running_var\n",
      "features.5.conv.0.1.num_batches_tracked\n",
      "features.5.conv.1.0.weight\n",
      "features.5.conv.1.1.weight\n",
      "features.5.conv.1.1.bias\n",
      "features.5.conv.1.1.running_mean\n",
      "features.5.conv.1.1.running_var\n",
      "features.5.conv.1.1.num_batches_tracked\n",
      "features.5.conv.2.weight\n",
      "features.5.conv.3.weight\n",
      "features.5.conv.3.bias\n",
      "features.5.conv.3.running_mean\n",
      "features.5.conv.3.running_var\n",
      "features.5.conv.3.num_batches_tracked\n",
      "features.6.conv.0.0.weight\n",
      "features.6.conv.0.1.weight\n",
      "features.6.conv.0.1.bias\n",
      "features.6.conv.0.1.running_mean\n",
      "features.6.conv.0.1.running_var\n",
      "features.6.conv.0.1.num_batches_tracked\n",
      "features.6.conv.1.0.weight\n",
      "features.6.conv.1.1.weight\n",
      "features.6.conv.1.1.bias\n",
      "features.6.conv.1.1.running_mean\n",
      "features.6.conv.1.1.running_var\n",
      "features.6.conv.1.1.num_batches_tracked\n",
      "features.6.conv.2.weight\n",
      "features.6.conv.3.weight\n",
      "features.6.conv.3.bias\n",
      "features.6.conv.3.running_mean\n",
      "features.6.conv.3.running_var\n",
      "features.6.conv.3.num_batches_tracked\n",
      "features.7.conv.0.0.weight\n",
      "features.7.conv.0.1.weight\n",
      "features.7.conv.0.1.bias\n",
      "features.7.conv.0.1.running_mean\n",
      "features.7.conv.0.1.running_var\n",
      "features.7.conv.0.1.num_batches_tracked\n",
      "features.7.conv.1.0.weight\n",
      "features.7.conv.1.1.weight\n",
      "features.7.conv.1.1.bias\n",
      "features.7.conv.1.1.running_mean\n",
      "features.7.conv.1.1.running_var\n",
      "features.7.conv.1.1.num_batches_tracked\n",
      "features.7.conv.2.weight\n",
      "features.7.conv.3.weight\n",
      "features.7.conv.3.bias\n",
      "features.7.conv.3.running_mean\n",
      "features.7.conv.3.running_var\n",
      "features.7.conv.3.num_batches_tracked\n",
      "features.8.conv.0.0.weight\n",
      "features.8.conv.0.1.weight\n",
      "features.8.conv.0.1.bias\n",
      "features.8.conv.0.1.running_mean\n",
      "features.8.conv.0.1.running_var\n",
      "features.8.conv.0.1.num_batches_tracked\n",
      "features.8.conv.1.0.weight\n",
      "features.8.conv.1.1.weight\n",
      "features.8.conv.1.1.bias\n",
      "features.8.conv.1.1.running_mean\n",
      "features.8.conv.1.1.running_var\n",
      "features.8.conv.1.1.num_batches_tracked\n",
      "features.8.conv.2.weight\n",
      "features.8.conv.3.weight\n",
      "features.8.conv.3.bias\n",
      "features.8.conv.3.running_mean\n",
      "features.8.conv.3.running_var\n",
      "features.8.conv.3.num_batches_tracked\n",
      "features.9.conv.0.0.weight\n",
      "features.9.conv.0.1.weight\n",
      "features.9.conv.0.1.bias\n",
      "features.9.conv.0.1.running_mean\n",
      "features.9.conv.0.1.running_var\n",
      "features.9.conv.0.1.num_batches_tracked\n",
      "features.9.conv.1.0.weight\n",
      "features.9.conv.1.1.weight\n",
      "features.9.conv.1.1.bias\n",
      "features.9.conv.1.1.running_mean\n",
      "features.9.conv.1.1.running_var\n",
      "features.9.conv.1.1.num_batches_tracked\n",
      "features.9.conv.2.weight\n",
      "features.9.conv.3.weight\n",
      "features.9.conv.3.bias\n",
      "features.9.conv.3.running_mean\n",
      "features.9.conv.3.running_var\n",
      "features.9.conv.3.num_batches_tracked\n",
      "features.10.conv.0.0.weight\n",
      "features.10.conv.0.1.weight\n",
      "features.10.conv.0.1.bias\n",
      "features.10.conv.0.1.running_mean\n",
      "features.10.conv.0.1.running_var\n",
      "features.10.conv.0.1.num_batches_tracked\n",
      "features.10.conv.1.0.weight\n",
      "features.10.conv.1.1.weight\n",
      "features.10.conv.1.1.bias\n",
      "features.10.conv.1.1.running_mean\n",
      "features.10.conv.1.1.running_var\n",
      "features.10.conv.1.1.num_batches_tracked\n",
      "features.10.conv.2.weight\n",
      "features.10.conv.3.weight\n",
      "features.10.conv.3.bias\n",
      "features.10.conv.3.running_mean\n",
      "features.10.conv.3.running_var\n",
      "features.10.conv.3.num_batches_tracked\n",
      "features.11.conv.0.0.weight\n",
      "features.11.conv.0.1.weight\n",
      "features.11.conv.0.1.bias\n",
      "features.11.conv.0.1.running_mean\n",
      "features.11.conv.0.1.running_var\n",
      "features.11.conv.0.1.num_batches_tracked\n",
      "features.11.conv.1.0.weight\n",
      "features.11.conv.1.1.weight\n",
      "features.11.conv.1.1.bias\n",
      "features.11.conv.1.1.running_mean\n",
      "features.11.conv.1.1.running_var\n",
      "features.11.conv.1.1.num_batches_tracked\n",
      "features.11.conv.2.weight\n",
      "features.11.conv.3.weight\n",
      "features.11.conv.3.bias\n",
      "features.11.conv.3.running_mean\n",
      "features.11.conv.3.running_var\n",
      "features.11.conv.3.num_batches_tracked\n",
      "features.12.conv.0.0.weight\n",
      "features.12.conv.0.1.weight\n",
      "features.12.conv.0.1.bias\n",
      "features.12.conv.0.1.running_mean\n",
      "features.12.conv.0.1.running_var\n",
      "features.12.conv.0.1.num_batches_tracked\n",
      "features.12.conv.1.0.weight\n",
      "features.12.conv.1.1.weight\n",
      "features.12.conv.1.1.bias\n",
      "features.12.conv.1.1.running_mean\n",
      "features.12.conv.1.1.running_var\n",
      "features.12.conv.1.1.num_batches_tracked\n",
      "features.12.conv.2.weight\n",
      "features.12.conv.3.weight\n",
      "features.12.conv.3.bias\n",
      "features.12.conv.3.running_mean\n",
      "features.12.conv.3.running_var\n",
      "features.12.conv.3.num_batches_tracked\n",
      "features.13.conv.0.0.weight\n",
      "features.13.conv.0.1.weight\n",
      "features.13.conv.0.1.bias\n",
      "features.13.conv.0.1.running_mean\n",
      "features.13.conv.0.1.running_var\n",
      "features.13.conv.0.1.num_batches_tracked\n",
      "features.13.conv.1.0.weight\n",
      "features.13.conv.1.1.weight\n",
      "features.13.conv.1.1.bias\n",
      "features.13.conv.1.1.running_mean\n",
      "features.13.conv.1.1.running_var\n",
      "features.13.conv.1.1.num_batches_tracked\n",
      "features.13.conv.2.weight\n",
      "features.13.conv.3.weight\n",
      "features.13.conv.3.bias\n",
      "features.13.conv.3.running_mean\n",
      "features.13.conv.3.running_var\n",
      "features.13.conv.3.num_batches_tracked\n",
      "features.14.conv.0.0.weight\n",
      "features.14.conv.0.1.weight\n",
      "features.14.conv.0.1.bias\n",
      "features.14.conv.0.1.running_mean\n",
      "features.14.conv.0.1.running_var\n",
      "features.14.conv.0.1.num_batches_tracked\n",
      "features.14.conv.1.0.weight\n",
      "features.14.conv.1.1.weight\n",
      "features.14.conv.1.1.bias\n",
      "features.14.conv.1.1.running_mean\n",
      "features.14.conv.1.1.running_var\n",
      "features.14.conv.1.1.num_batches_tracked\n",
      "features.14.conv.2.weight\n",
      "features.14.conv.3.weight\n",
      "features.14.conv.3.bias\n",
      "features.14.conv.3.running_mean\n",
      "features.14.conv.3.running_var\n",
      "features.14.conv.3.num_batches_tracked\n",
      "features.15.conv.0.0.weight\n",
      "features.15.conv.0.1.weight\n",
      "features.15.conv.0.1.bias\n",
      "features.15.conv.0.1.running_mean\n",
      "features.15.conv.0.1.running_var\n",
      "features.15.conv.0.1.num_batches_tracked\n",
      "features.15.conv.1.0.weight\n",
      "features.15.conv.1.1.weight\n",
      "features.15.conv.1.1.bias\n",
      "features.15.conv.1.1.running_mean\n",
      "features.15.conv.1.1.running_var\n",
      "features.15.conv.1.1.num_batches_tracked\n",
      "features.15.conv.2.weight\n",
      "features.15.conv.3.weight\n",
      "features.15.conv.3.bias\n",
      "features.15.conv.3.running_mean\n",
      "features.15.conv.3.running_var\n",
      "features.15.conv.3.num_batches_tracked\n",
      "features.16.conv.0.0.weight\n",
      "features.16.conv.0.1.weight\n",
      "features.16.conv.0.1.bias\n",
      "features.16.conv.0.1.running_mean\n",
      "features.16.conv.0.1.running_var\n",
      "features.16.conv.0.1.num_batches_tracked\n",
      "features.16.conv.1.0.weight\n",
      "features.16.conv.1.1.weight\n",
      "features.16.conv.1.1.bias\n",
      "features.16.conv.1.1.running_mean\n",
      "features.16.conv.1.1.running_var\n",
      "features.16.conv.1.1.num_batches_tracked\n",
      "features.16.conv.2.weight\n",
      "features.16.conv.3.weight\n",
      "features.16.conv.3.bias\n",
      "features.16.conv.3.running_mean\n",
      "features.16.conv.3.running_var\n",
      "features.16.conv.3.num_batches_tracked\n",
      "features.17.conv.0.0.weight\n",
      "features.17.conv.0.1.weight\n",
      "features.17.conv.0.1.bias\n",
      "features.17.conv.0.1.running_mean\n",
      "features.17.conv.0.1.running_var\n",
      "features.17.conv.0.1.num_batches_tracked\n",
      "features.17.conv.1.0.weight\n",
      "features.17.conv.1.1.weight\n",
      "features.17.conv.1.1.bias\n",
      "features.17.conv.1.1.running_mean\n",
      "features.17.conv.1.1.running_var\n",
      "features.17.conv.1.1.num_batches_tracked\n",
      "features.17.conv.2.weight\n",
      "features.17.conv.3.weight\n",
      "features.17.conv.3.bias\n",
      "features.17.conv.3.running_mean\n",
      "features.17.conv.3.running_var\n",
      "features.17.conv.3.num_batches_tracked\n",
      "features.18.0.weight\n",
      "features.18.1.weight\n",
      "features.18.1.bias\n",
      "features.18.1.running_mean\n",
      "features.18.1.running_var\n",
      "features.18.1.num_batches_tracked\n",
      "classifier.1.weight\n",
      "classifier.1.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0.0088\n",
    "params_atk = temp_atk_model.state_dict()\n",
    "# first make the model with empty weights\n",
    "new_model = copy.deepcopy(model_FAT)\n",
    "new_model.eval()\n",
    "new_weight_dict = copy.deepcopy(params_FAT)\n",
    "for key in new_weight_dict.keys():\n",
    "    print(key)\n",
    "    new_weight_dict[key] = a*params_atk[key] + (1-a)*params_FAT[key] \n",
    "new_model.load_state_dict(new_weight_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(113.6804)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_scale[a_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc:  0.8549999952316284  ( 0.0646988174655441 )  adv acc:  0.010312500153668224  ( 0.009636965109295265 ) \n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_global = aggregator.global_learners_ensemble[0].model\n",
    "model_client = aggregator.clients[1].learners_ensemble[0].model\n",
    "\n",
    "acc, adv_acc = get_adv_acc(aggregator, new_model, eps=eps_attack, step_size = step_size, steps = steps)\n",
    "print(\"Test acc: \", np.mean(acc), \" (\", np.std(acc),\") \", \"adv acc: \", np.mean(adv_acc),\" (\", np.std(adv_acc),\") \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.6040e-02, -1.7314e-02, -2.9185e-02,  3.6448e-02, -4.7945e-02,\n",
       "        -3.2198e-02, -1.2044e-01,  9.3056e-02, -1.2594e-01, -3.4998e-03,\n",
       "        -1.0203e-01, -2.3453e-03,  9.0848e-02, -1.0762e-01,  7.5059e-02,\n",
       "         3.4159e-02, -6.5809e-02, -9.1424e-02,  5.9271e-02, -1.6213e-01,\n",
       "        -3.8093e-02,  1.7239e-01, -3.9066e-02, -7.3285e-03,  3.5023e-02,\n",
       "        -9.2273e-02,  1.6514e-01, -7.8947e-02, -1.5671e-01, -8.0183e-02,\n",
       "         1.4583e-01,  3.8248e-02, -3.7716e-02, -4.0461e-02,  4.6975e-02,\n",
       "         1.4656e-01, -6.9432e-02,  9.6042e-02, -1.0139e-02, -1.0109e-01,\n",
       "        -2.0836e-01,  1.0307e-01, -7.5671e-02, -8.8814e-03, -1.2926e-02,\n",
       "        -1.5424e-01, -9.2713e-03,  1.1414e-01, -6.6919e-02, -1.8199e-01,\n",
       "         7.6220e-02, -7.8709e-02,  6.3101e-02,  4.2614e-02, -6.2896e-03,\n",
       "        -6.1512e-02,  6.4384e-02,  6.9918e-02, -2.3017e-02, -1.4033e-01,\n",
       "        -1.1360e-02,  1.3197e-02, -4.6689e-03,  1.7533e-02, -1.0762e-01,\n",
       "        -4.3535e-02, -2.8164e-01,  5.6919e-02,  3.3232e-03, -2.1697e-02,\n",
       "        -4.5889e-02,  6.6690e-02, -1.4173e-01,  1.7064e-01,  5.2756e-02,\n",
       "        -1.6437e-01,  4.0854e-02,  3.9177e-02, -1.4461e-01, -9.0385e-02,\n",
       "         2.7665e-02,  9.1732e-02,  5.8898e-02, -1.8912e-01,  1.2463e-01,\n",
       "         1.3438e-01, -6.9281e-02, -2.9743e-01, -1.2960e-01,  1.1966e-01,\n",
       "         2.1540e-02, -1.0982e-01,  4.8746e-02,  1.2305e-01, -1.6032e-01,\n",
       "        -2.4557e-01, -2.7322e-02, -5.1112e-02,  1.8678e-01, -9.5117e-02,\n",
       "        -1.4700e-01, -4.1813e-02,  1.0164e-02, -1.3436e-02,  1.7125e-01,\n",
       "         1.4338e-01, -2.3364e-01, -1.8126e-02,  1.8204e-01, -1.8743e-01,\n",
       "         7.9431e-02,  1.1634e-02, -5.4422e-02, -1.8704e-01, -5.8719e-02,\n",
       "         1.6766e-01, -5.8550e-02, -1.5855e-01,  1.0957e-01, -4.4771e-02,\n",
       "        -5.0864e-02, -1.4043e-01,  6.3612e-02,  8.6569e-02,  9.2211e-03,\n",
       "        -1.6375e-03, -1.5914e-02, -3.0081e-02,  5.9145e-02, -1.3064e-01,\n",
       "        -2.1597e-01, -6.7218e-02,  5.5844e-02, -2.1458e-02,  1.1226e-01,\n",
       "         5.5125e-02,  7.6296e-02,  3.6245e-04, -1.1977e-01, -6.6622e-02,\n",
       "        -9.0153e-02,  1.1502e-01, -3.7819e-02,  1.0632e-01,  1.6360e-01,\n",
       "         7.9928e-02, -1.1446e-01,  2.5777e-03,  1.1006e-01, -4.8131e-02,\n",
       "        -3.4211e-02, -1.5261e-01, -4.4081e-02,  6.5876e-02,  6.9102e-02,\n",
       "         1.1911e-01,  1.0865e-01, -5.1248e-02, -1.2388e-01, -3.0040e-01,\n",
       "         7.9435e-02,  4.5186e-02,  1.2296e-01, -1.6916e-01, -1.0976e-02,\n",
       "        -9.9883e-02, -1.6143e-01,  2.4847e-02, -8.9558e-02,  8.0064e-02,\n",
       "        -7.4960e-02, -6.6519e-02,  2.1552e-01,  1.1291e-01, -6.4542e-02,\n",
       "         1.1792e-01,  2.4414e-02,  1.1398e-02, -1.7167e-01,  2.4511e-02,\n",
       "         4.5515e-02,  1.6954e-01,  2.3891e-02,  1.7208e-01,  1.4010e-01,\n",
       "        -3.4317e-02, -9.5378e-02, -1.3633e-01,  1.0256e-01,  1.2153e-02,\n",
       "         1.4162e-02, -9.1165e-02,  2.6627e-02,  1.5641e-01, -7.8485e-02,\n",
       "         1.1380e-01, -1.7089e-01, -3.3213e-02,  1.5701e-01,  2.0473e-01,\n",
       "        -1.0536e-01,  6.2950e-02, -1.5048e-01,  4.3901e-02, -3.6676e-02,\n",
       "         6.7760e-02, -1.4530e-01, -1.4678e-01, -2.1413e-01,  4.9908e-02,\n",
       "        -1.6843e-01,  1.6889e-01, -9.9158e-02,  4.1798e-02, -6.6160e-02,\n",
       "         4.3790e-02, -6.7438e-03, -2.3865e-02, -7.6565e-02, -3.0975e-02,\n",
       "         1.8279e-02,  2.0049e-02,  6.0150e-02,  9.5573e-02,  3.3296e-02,\n",
       "        -1.9828e-01, -4.0071e-02, -6.0428e-02,  2.4591e-03, -2.3794e-01,\n",
       "        -9.4322e-02,  3.1459e-02, -4.6800e-02, -1.2932e-01, -1.1282e-01,\n",
       "         9.4671e-02, -1.0801e-01, -1.0908e-01,  8.4833e-02, -7.0927e-03,\n",
       "         7.9726e-02,  1.2005e-01,  1.0826e-01,  1.6316e-03,  1.2060e-01,\n",
       "         4.8732e-02, -2.9829e-01,  4.9668e-02,  8.4533e-02,  3.3406e-02,\n",
       "         3.7916e-02,  1.2036e-01,  4.4937e-02, -7.7189e-02, -3.4651e-02,\n",
       "         9.5261e-02, -1.0343e-01, -2.6335e-02,  4.8757e-02, -5.1352e-02,\n",
       "         8.5350e-02, -7.3145e-02,  2.8590e-02, -1.4429e-02, -9.3625e-02,\n",
       "        -5.6333e-02, -1.1697e-01, -2.5137e-02, -5.6639e-02,  1.1422e-01,\n",
       "        -5.9634e-02,  1.0425e-01,  1.8007e-01, -1.0729e-01, -2.4073e-02,\n",
       "         1.9404e-02, -5.4419e-02,  1.4451e-01, -3.3155e-01, -9.8334e-02,\n",
       "         6.9027e-02, -7.1331e-02, -7.8685e-02, -1.0560e-01,  1.0212e-01,\n",
       "         2.5211e-02, -4.8578e-03,  8.4862e-02,  3.0801e-02, -1.0382e-01,\n",
       "        -2.2852e-01,  3.5694e-01,  5.6091e-02, -3.0367e-04,  3.2232e-02,\n",
       "         1.0176e-01, -7.8286e-02,  5.3860e-02,  2.1651e-02,  1.7938e-01,\n",
       "         1.2019e-01, -9.5661e-02,  5.5916e-02,  3.5563e-02,  7.4291e-02,\n",
       "        -1.0779e-02,  1.3113e-01, -2.0272e-01, -1.8199e-02, -3.9319e-02,\n",
       "        -1.8165e-01, -4.4405e-02,  7.5860e-02,  1.8247e-02,  9.4517e-02,\n",
       "         1.2481e-01, -2.9635e-03,  1.3713e-01, -1.6092e-01,  7.7744e-02],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_global.state_dict()['features.17.conv.3.running_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2566e+00,  1.7568e-01,  5.3032e-01,  4.8528e-01,  1.4230e+00,\n",
       "        -4.8630e-01,  2.6665e+00, -1.7887e+00, -1.9969e+00, -2.3407e+00,\n",
       "        -2.7083e+00, -1.6274e+00,  2.9390e+00, -2.1259e-01,  3.3210e+00,\n",
       "         1.2216e+00, -2.2020e-01,  5.0330e-01, -5.3409e-01,  1.2406e+00,\n",
       "         3.9915e-02, -3.1031e-01,  1.8286e+00, -8.7779e-01,  7.3021e-01,\n",
       "         1.5077e+00,  1.7277e-01,  5.6840e-01,  1.7641e+00,  2.4147e+00,\n",
       "         3.3031e-01,  1.0210e+00, -7.3006e-01, -1.5028e-01, -2.4561e+00,\n",
       "         6.0343e-01,  2.7003e+00,  1.3169e+00,  7.4770e-01,  5.8609e-01,\n",
       "         1.7782e+00, -1.1555e+00,  2.4197e+00, -8.3227e-01,  1.6366e-01,\n",
       "         7.0821e-01,  1.6835e+00, -1.4294e+00, -1.6206e+00,  2.8456e+00,\n",
       "         1.4537e+00,  1.2339e+00,  7.5515e-01, -8.6303e-01, -2.6035e+00,\n",
       "        -1.3260e+00, -2.5312e+00, -5.6667e-01,  1.9192e+00, -1.2794e-01,\n",
       "        -2.0182e-01,  1.3990e+00, -1.9876e+00,  8.8675e-01,  2.3395e+00,\n",
       "        -5.6239e-02, -9.2445e-01,  1.1243e+00, -4.7683e-01,  1.7838e-01,\n",
       "        -2.3177e+00, -5.1655e-02,  1.7211e-02, -1.0050e+00,  2.2482e-01,\n",
       "        -9.2386e-01, -5.9216e-01,  1.0266e+00, -3.0231e+00, -8.6523e-01,\n",
       "        -4.8668e-01, -6.1123e-01, -2.4575e+00, -1.3748e+00, -7.6725e-01,\n",
       "         1.7513e+00,  2.2755e+00, -3.4923e-01,  1.4805e+00, -1.0992e+00,\n",
       "        -1.2565e+00, -1.2545e+00,  6.5932e-02,  8.6266e-01, -6.5161e-01,\n",
       "        -5.8863e-01, -2.0579e+00,  2.0837e+00, -1.7744e+00, -1.2419e+00,\n",
       "        -6.8893e-01, -3.1501e+00, -1.4553e-01,  1.7754e-01, -2.0559e+00,\n",
       "        -2.0182e+00,  9.2894e-01, -1.1198e-02, -3.6483e+00,  1.2961e+00,\n",
       "        -7.4352e-02, -9.9076e-01,  2.7308e+00, -1.7181e-01, -2.7505e+00,\n",
       "        -6.6592e-01,  8.2320e-01,  1.0825e+00,  9.1198e-01, -3.2230e-01,\n",
       "        -2.4357e+00,  4.7250e+00, -2.3248e+00, -1.6616e+00, -1.6818e-01,\n",
       "        -1.2506e+00, -5.8366e-02,  2.0798e+00,  1.9115e+00,  6.5621e-01,\n",
       "         8.0786e-01, -1.0082e+00, -3.9795e+00, -2.0889e-01, -2.2331e+00,\n",
       "        -1.5416e+00,  5.0467e-02,  4.8611e-02,  5.6857e+00, -1.0800e+00,\n",
       "        -2.0853e+00, -3.7983e+00,  2.1436e+00,  1.3719e+00, -2.0604e-01,\n",
       "        -3.1813e+00,  1.0748e+00,  1.6990e+00, -6.1685e-01, -1.9442e+00,\n",
       "        -1.3193e+00,  4.0846e-01,  5.7747e-02, -6.9766e-01, -2.1640e+00,\n",
       "        -3.4398e+00,  1.1852e+00,  2.7216e+00,  3.3651e-01,  3.0447e+00,\n",
       "         1.4513e+00,  3.1511e+00,  4.8128e-01, -9.2700e-01,  1.3912e+00,\n",
       "         2.8285e-02, -6.7496e-02,  2.3929e+00, -1.7580e-01, -1.1964e+00,\n",
       "        -1.1805e+00,  6.1345e-01, -2.1791e+00, -5.9205e-01,  2.0357e-01,\n",
       "        -3.5557e-01,  1.3760e-01,  1.0969e+00, -2.4034e+00,  3.0039e+00,\n",
       "        -1.0367e+00, -2.8512e-01,  2.0407e+00, -1.4644e+00, -7.7746e-02,\n",
       "        -1.3430e+00, -1.5281e-01, -5.1230e-01, -2.9519e-01,  3.7000e+00,\n",
       "        -2.1135e+00,  2.7592e-02,  1.8648e+00,  4.3098e-01, -1.5802e+00,\n",
       "         1.7519e-01, -2.2323e+00, -1.3720e-01, -7.1405e-01, -1.5805e-01,\n",
       "        -1.1364e+00,  2.9374e+00,  2.6859e+00, -1.1959e+00,  2.7668e+00,\n",
       "         9.5595e-01,  1.3705e+00,  3.8616e-01,  1.1813e+00, -1.9095e+00,\n",
       "         1.7532e+00, -1.6312e+00,  4.7299e-02, -2.7158e-03, -1.4060e+00,\n",
       "         2.1266e-01,  2.5598e+00, -2.9801e+00, -3.4004e-02,  2.1459e+00,\n",
       "        -6.8954e-01, -7.8529e-01, -2.2855e+00, -9.0563e-01, -9.4200e-01,\n",
       "         3.9361e+00,  3.5233e-01,  6.5301e-02, -7.8566e-01,  1.2777e+00,\n",
       "         9.8882e-01,  5.1738e-01, -1.1204e+00,  1.0112e+00,  2.0682e+00,\n",
       "         4.0823e+00,  1.0423e+00,  9.4819e-01,  5.2404e-01, -5.9341e-01,\n",
       "         1.3936e+00,  4.0360e-01,  4.0633e-01,  1.9307e+00, -7.9432e-01,\n",
       "         1.9437e+00, -1.6187e+00, -1.9314e+00, -8.5585e-01, -3.5943e+00,\n",
       "        -1.0641e+00,  8.8310e-01,  9.6468e-01,  1.3558e+00, -6.4043e-01,\n",
       "        -9.7415e-01,  2.3048e-01, -1.2179e+00,  4.0816e+00, -1.4491e+00,\n",
       "         9.9309e-01, -2.2504e+00, -1.0107e+00,  1.3924e+00,  6.2927e-01,\n",
       "         2.6763e+00, -5.1764e-01,  1.5365e+00,  6.9605e-01,  1.0448e+00,\n",
       "         2.3163e-01, -1.6077e-01, -1.1439e-01,  2.8428e+00, -5.6594e-01,\n",
       "        -1.5591e+00, -3.2247e+00,  8.5759e-02, -3.4399e-01,  9.9383e-01,\n",
       "         1.8448e+00,  1.3705e+00,  2.2780e+00,  2.5312e+00, -5.8320e-01,\n",
       "         1.7925e+00,  7.8182e-01, -3.7456e+00, -2.2226e+00,  1.8067e+00,\n",
       "         1.3304e+00, -7.3017e-01, -9.8397e-01, -1.8833e+00,  7.6583e-01,\n",
       "         5.1696e-01, -2.3377e+00, -2.6519e-01,  1.5474e-02, -3.0361e+00,\n",
       "         2.9065e+00, -5.9857e-01, -1.5387e-01, -7.2775e-01, -1.5783e+00,\n",
       "         3.8820e-01, -5.9362e-01,  2.4014e+00, -9.0679e-01,  4.5810e-01,\n",
       "        -3.2148e+00,  1.7852e+00, -4.5444e-01, -2.0828e+00, -1.3516e+00,\n",
       "        -1.3462e+00, -2.0401e+00, -6.4705e-02,  6.6786e-01,  1.2783e+00],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_atk_model.state_dict()['features.17.conv.3.running_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedEM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
