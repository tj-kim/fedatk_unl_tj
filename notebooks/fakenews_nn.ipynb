{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fedatk_unl_tj\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/FedEM_env/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/ubuntu/anaconda3/envs/FedEM_env/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Run Experiment\n",
    "\n",
    "This script allows to run one federated learning experiment; the experiment name, the method and the\n",
    "number of clients/tasks should be precised along side with the hyper-parameters of the experiment.\n",
    "\n",
    "The results of the experiment (i.e., training logs) are written to ./logs/ folder.\n",
    "\n",
    "This file can also be imported as a module and contains the following function:\n",
    "\n",
    "    * run_experiment - runs one experiments given its arguments\n",
    "\"\"\"\n",
    "\n",
    "# Import General Libraries\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numba \n",
    "\n",
    "import sys\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.constants import *\n",
    "from utils.args import *\n",
    "from run_experiment import * \n",
    "from models import *\n",
    "\n",
    "\n",
    "# Import Transfer Attack\n",
    "from transfer_attacks.Personalized_NN import *\n",
    "from transfer_attacks.Params import *\n",
    "from transfer_attacks.Transferer import *\n",
    "from transfer_attacks.Args import *\n",
    "from transfer_attacks.TA_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running trial: 0\n",
      "==> Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:01<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 23.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.693 | Train Acc: 50.378% |Test Loss: 0.693 | Test Acc: 48.500% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.693 | Train Acc: 50.378% |Test Loss: 0.693 | Test Acc: 48.500% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "################################################################################\n",
      "Training..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/home/ubuntu/fedatk_unl_tj/learners/learner.py:190: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)\n",
      "  loss = (loss_vec.T @ weights[indices]) / loss_vec.size(0)\n",
      " 18%|█▊        | 9/50 [00:03<00:15,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.690 | Train Acc: 50.378% |Test Loss: 0.691 | Test Acc: 48.500% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:04<00:20,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.690 | Train Acc: 50.378% |Test Loss: 0.691 | Test Acc: 48.500% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:33<01:29,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.644 | Train Acc: 71.871% |Test Loss: 0.644 | Test Acc: 72.286% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:36<01:28,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.644 | Train Acc: 71.871% |Test Loss: 0.644 | Test Acc: 72.286% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [01:06<01:03,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.561 | Train Acc: 77.050% |Test Loss: 0.566 | Test Acc: 76.071% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [01:10<01:05,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.561 | Train Acc: 77.050% |Test Loss: 0.566 | Test Acc: 76.071% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [01:41<00:33,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.571 | Train Acc: 76.259% |Test Loss: 0.578 | Test Acc: 74.786% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:44<00:31,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.571 | Train Acc: 76.259% |Test Loss: 0.578 | Test Acc: 74.786% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [02:14<00:03,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.576 | Train Acc: 75.989% |Test Loss: 0.584 | Test Acc: 74.500% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:18<00:00,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.576 | Train Acc: 75.989% |Test Loss: 0.584 | Test Acc: 74.500% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [02:25,  4.43s/it]                        "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# os.chdir(parent_dir) # As we are in a folder\n",
    "\n",
    "dataset = \"fakenewsnet\"\n",
    "exp_names =['FAT_R50_ep02']#  ['FedAvg']   \n",
    "exp_method =   ['FedAvg_adv'] # ['FedAvg']\n",
    "save_folder = 'weights/fakenews/250119_small_architecture_moreconv/'\n",
    "\n",
    "exp_num_learners = 1\n",
    "exp_lr = 0.01\n",
    "num_rounds = 50\n",
    "num_clients = 20\n",
    "FAT_start_round = 10\n",
    "    \n",
    "for itt in range(len(exp_names)):\n",
    "    \n",
    "    print(\"running trial:\", itt)\n",
    "    \n",
    "    # Manually set argument parameters\n",
    "    args_ = Args()\n",
    "    args_.experiment = dataset\n",
    "    args_.method = exp_method[itt]\n",
    "    args_.decentralized = False\n",
    "    args_.sampling_rate = 1.0\n",
    "    args_.input_dimension = None\n",
    "    args_.output_dimension = None\n",
    "    args_.n_learners= exp_num_learners\n",
    "    args_.n_rounds = num_rounds\n",
    "    args_.bz = 128\n",
    "    args_.local_steps = 1\n",
    "    args_.lr_lambda = 0\n",
    "    args_.lr = exp_lr\n",
    "    args_.lr_scheduler = 'multi_step'\n",
    "    args_.log_freq = 10\n",
    "    args_.device = 'cuda'\n",
    "    args_.optimizer = 'sgd'\n",
    "    args_.mu = 0\n",
    "    args_.communication_probability = 0.1\n",
    "    args_.q = 1\n",
    "    args_.locally_tune_clients = False\n",
    "    args_.seed = 1234\n",
    "    args_.verbose = 1\n",
    "    args_.save_path = save_folder + exp_names[itt]\n",
    "    args_.validation = False\n",
    "    args_.save_freq = 10\n",
    "\n",
    "    # Other Argument Parameters\n",
    "    Q = 10 # update per round\n",
    "    G = 0.5\n",
    "    S = 0.05 # Threshold\n",
    "    step_size = 0.01\n",
    "    K = 10\n",
    "    eps = 0.2\n",
    "\n",
    "    # Randomized Parameters\n",
    "    # Ru = np.random.uniform(0, 0.5, size=num_clients)\n",
    "    Ru = np.ones(num_clients)\n",
    "    \n",
    "    # Generate the dummy values here\n",
    "    aggregator, clients = dummy_aggregator(args_, num_clients)\n",
    "\n",
    "    # Change client datset\n",
    "    for i in range(len(clients)):\n",
    "        aggregator.clients[i].dataset_name = dataset\n",
    "\n",
    "    # Set attack parameters\n",
    "    if exp_method[itt] == 'FedAvg_adv':\n",
    "        x_min = torch.min(clients[0].adv_nn.dataloader.x_data)\n",
    "        x_max = torch.max(clients[0].adv_nn.dataloader.x_data)\n",
    "        atk_params = PGD_Params()\n",
    "        atk_params.set_params(batch_size=1, iteration = K,\n",
    "                        target = -1, x_val_min = x_min, x_val_max = x_max,\n",
    "                        step_size = 0.05, step_norm = \"inf\", eps = eps, eps_norm = 2)\n",
    "\n",
    "    # Obtain the central controller decision making variables (static)\n",
    "    num_h = args_.n_learners= 3\n",
    "    Du = np.zeros(len(clients))\n",
    "\n",
    "    for i in range(len(clients)):\n",
    "        num_data = clients[i].train_iterator.dataset.targets.shape[0]\n",
    "        Du[i] = num_data\n",
    "    D = np.sum(Du) # Total number of data points\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Training..\")\n",
    "    pbar = tqdm(total=args_.n_rounds)\n",
    "    current_round = 0\n",
    "    while current_round <= args_.n_rounds:\n",
    "\n",
    "        if exp_method[itt] == 'FedAvg_adv':\n",
    "            # If statement catching every Q rounds -- update dataset\n",
    "            if  current_round != 0 and current_round%Q == 0 and current_round >= FAT_start_round: # \n",
    "                # print(\"Round:\", current_round, \"Calculation Adv\")\n",
    "                # Obtaining hypothesis information\n",
    "                Whu = np.zeros([num_clients,num_h]) # Hypothesis weight for each user\n",
    "                for i in range(len(clients)):\n",
    "                    # print(\"client\", i)\n",
    "                    temp_client = aggregator.clients[i]\n",
    "                    hyp_weights = temp_client.learners_ensemble.learners_weights\n",
    "                    Whu[i] = hyp_weights\n",
    "\n",
    "                row_sums = Whu.sum(axis=1)\n",
    "                Whu = Whu / row_sums[:, np.newaxis]\n",
    "                Wh = np.sum(Whu,axis=0)/num_clients\n",
    "\n",
    "                # Solve for adversarial ratio at every client\n",
    "                # Fu = solve_proportions(G, num_clients, num_h, Du, Whu, S, Ru, step_size)\n",
    "                Fu = np.ones(num_clients) * G\n",
    "\n",
    "                # Assign proportion and attack params\n",
    "                for i in range(len(clients)):\n",
    "                    aggregator.clients[i].set_adv_params(Fu[i], atk_params)\n",
    "                    aggregator.clients[i].update_advnn()\n",
    "                    aggregator.clients[i].assign_advdataset()\n",
    "\n",
    "        aggregator.mix()\n",
    "        \n",
    "        # Save more often the intermediate NN\n",
    "        if current_round% args_.save_freq == 0:\n",
    "            if \"save_path\" in args_:\n",
    "                save_root = os.path.join(args_.save_path)\n",
    "\n",
    "                os.makedirs(save_root, exist_ok=True)\n",
    "#                     aggregator.save_state_intermed(save_root, current_round)\n",
    "\n",
    "        if aggregator.c_round != current_round:\n",
    "            pbar.update(1)\n",
    "            current_round = aggregator.c_round\n",
    "\n",
    "    if \"save_path\" in args_:\n",
    "        save_root = os.path.join(args_.save_path)\n",
    "\n",
    "        os.makedirs(save_root, exist_ok=True)\n",
    "        aggregator.save_state(save_root)\n",
    "        \n",
    "    # del args_, aggregator, clients\n",
    "    # torch.cuda.empty_cache()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedEM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
