{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Vector Pull for Direction\n",
    "\n",
    "Oct 31 2023\n",
    "TJ Kim\n",
    "\n",
    "##### Summary\n",
    "Load any NN model. Obtain layer by layer the unit direction vector (against vector of zeros). See if cosine similarity can be used as a metric to measure direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fedatk_unl_tj\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/fedatk_unl_tj/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import General Libraries\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import FedEM based Libraries\n",
    "from utils.utils import *\n",
    "from utils.constants import *\n",
    "from utils.args import *\n",
    "from utils.util_notebooks import *\n",
    "from run_experiment import *\n",
    "from models import *\n",
    "\n",
    "# Import Transfer Attack\n",
    "from transfer_attacks.Personalized_NN import *\n",
    "from transfer_attacks.Params import *\n",
    "from transfer_attacks.Transferer import *\n",
    "from transfer_attacks.Args import *\n",
    "from transfer_attacks.TA_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 163.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:15<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Test Clients initialization..\n",
      "===> Building data iterators..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Initializing clients..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 2.299 | Train Acc: 10.548% |Test Loss: 2.297 | Test Acc: 10.511% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "setting, num_user = \"FedAvg\", 40\n",
    "\n",
    "try: # Skip loading if already loaded\n",
    "    aggregator\n",
    "except:\n",
    "    aggregator, clients, args_ = set_args(setting, num_user)\n",
    "\n",
    "# Load models for FAT and FedAvg\n",
    "save_path_FAT = 'weights/cifar10/230922_baseline_train/FAT/'\n",
    "save_path_FedAvg = 'weights/cifar10/230922_baseline_train/fedavg/'\n",
    "\n",
    "model_FAT = copy.deepcopy(import_model_weights(num_user, setting, save_path_FAT, aggregator, args_)[0])\n",
    "model_Fedavg = import_model_weights(num_user, setting, save_path_FedAvg, aggregator, args_)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def matrix_cosine_similarity(mat1, mat2):\n",
    "    vec1 = mat1.cpu().numpy().flatten()\n",
    "    vec2 = mat2.cpu().numpy().flatten()\n",
    "    return cosine_similarity([vec1], [vec2])[0][0]\n",
    "\n",
    "def get_adv_acc(aggregator, model, batch_size = 500):\n",
    "    num_clients = len(aggregator.clients)\n",
    "    \n",
    "    # Dataloader for datax\n",
    "    data_x = []\n",
    "    daniloader = clients[0].val_iterator\n",
    "    for (x,y,idx) in daniloader.dataset:\n",
    "        data_x.append(x)\n",
    "\n",
    "    data_x = torch.stack(data_x)\n",
    "    victim_idxs = range(num_clients)\n",
    "\n",
    "    dataloader = load_client_data(clients = aggregator.clients, c_id = 0, mode = 'test')\n",
    "    batch_size = min(batch_size, dataloader.y_data.shape[0])\n",
    "\n",
    "    t1 = Transferer(models_list = [model] * num_clients, dataloader=dataloader)\n",
    "    t1.generate_victims(victim_idxs)\n",
    "    t1.atk_params = PGD_Params()\n",
    "    t1.atk_params.set_params(batch_size=batch_size, iteration = 10, target = -1,\n",
    "                             x_val_min = torch.min(data_x), x_val_max = torch.max(data_x),\n",
    "                             step_size = 0.05, step_norm = \"inf\", eps = 4, eps_norm = 2)\n",
    "    t1.generate_advNN(0)\n",
    "    t1.generate_xadv(atk_type=\"pgd\")\n",
    "    t1.send_to_victims(victim_idxs)\n",
    "\n",
    "    \n",
    "    return t1.adv_acc_transfers[0]\n",
    "\n",
    "def pull_model_from_agg(aggregator):\n",
    "        \n",
    "    # This is where the models are stored -- one for each mixture --> learner.model for nn\n",
    "    hypotheses = aggregator.global_learners_ensemble.learners\n",
    "\n",
    "    # obtain the state dict for each of the weights \n",
    "    weights_h = []\n",
    "\n",
    "    for h in hypotheses:\n",
    "        weights_h += [h.model.state_dict()]\n",
    "    \n",
    "    # first make the model with empty weights\n",
    "    new_model = copy.deepcopy(hypotheses[0].model)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain parameters for each layer\n",
    "params_FAT = model_FAT.state_dict()\n",
    "params_FedAvg = model_Fedavg.state_dict()\n",
    "\n",
    "# Just take the values of weights and bias for the model\n",
    "desired_keys = [key for key in params_FAT.keys() if 'weight' in key or 'bias' in key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features.0.0.weight', 'features.0.1.weight', 'features.0.1.bias', 'features.0.1.running_mean', 'features.0.1.running_var', 'features.0.1.num_batches_tracked', 'features.1.conv.0.0.weight', 'features.1.conv.0.1.weight', 'features.1.conv.0.1.bias', 'features.1.conv.0.1.running_mean', 'features.1.conv.0.1.running_var', 'features.1.conv.0.1.num_batches_tracked', 'features.1.conv.1.weight', 'features.1.conv.2.weight', 'features.1.conv.2.bias', 'features.1.conv.2.running_mean', 'features.1.conv.2.running_var', 'features.1.conv.2.num_batches_tracked', 'features.2.conv.0.0.weight', 'features.2.conv.0.1.weight', 'features.2.conv.0.1.bias', 'features.2.conv.0.1.running_mean', 'features.2.conv.0.1.running_var', 'features.2.conv.0.1.num_batches_tracked', 'features.2.conv.1.0.weight', 'features.2.conv.1.1.weight', 'features.2.conv.1.1.bias', 'features.2.conv.1.1.running_mean', 'features.2.conv.1.1.running_var', 'features.2.conv.1.1.num_batches_tracked', 'features.2.conv.2.weight', 'features.2.conv.3.weight', 'features.2.conv.3.bias', 'features.2.conv.3.running_mean', 'features.2.conv.3.running_var', 'features.2.conv.3.num_batches_tracked', 'features.3.conv.0.0.weight', 'features.3.conv.0.1.weight', 'features.3.conv.0.1.bias', 'features.3.conv.0.1.running_mean', 'features.3.conv.0.1.running_var', 'features.3.conv.0.1.num_batches_tracked', 'features.3.conv.1.0.weight', 'features.3.conv.1.1.weight', 'features.3.conv.1.1.bias', 'features.3.conv.1.1.running_mean', 'features.3.conv.1.1.running_var', 'features.3.conv.1.1.num_batches_tracked', 'features.3.conv.2.weight', 'features.3.conv.3.weight', 'features.3.conv.3.bias', 'features.3.conv.3.running_mean', 'features.3.conv.3.running_var', 'features.3.conv.3.num_batches_tracked', 'features.4.conv.0.0.weight', 'features.4.conv.0.1.weight', 'features.4.conv.0.1.bias', 'features.4.conv.0.1.running_mean', 'features.4.conv.0.1.running_var', 'features.4.conv.0.1.num_batches_tracked', 'features.4.conv.1.0.weight', 'features.4.conv.1.1.weight', 'features.4.conv.1.1.bias', 'features.4.conv.1.1.running_mean', 'features.4.conv.1.1.running_var', 'features.4.conv.1.1.num_batches_tracked', 'features.4.conv.2.weight', 'features.4.conv.3.weight', 'features.4.conv.3.bias', 'features.4.conv.3.running_mean', 'features.4.conv.3.running_var', 'features.4.conv.3.num_batches_tracked', 'features.5.conv.0.0.weight', 'features.5.conv.0.1.weight', 'features.5.conv.0.1.bias', 'features.5.conv.0.1.running_mean', 'features.5.conv.0.1.running_var', 'features.5.conv.0.1.num_batches_tracked', 'features.5.conv.1.0.weight', 'features.5.conv.1.1.weight', 'features.5.conv.1.1.bias', 'features.5.conv.1.1.running_mean', 'features.5.conv.1.1.running_var', 'features.5.conv.1.1.num_batches_tracked', 'features.5.conv.2.weight', 'features.5.conv.3.weight', 'features.5.conv.3.bias', 'features.5.conv.3.running_mean', 'features.5.conv.3.running_var', 'features.5.conv.3.num_batches_tracked', 'features.6.conv.0.0.weight', 'features.6.conv.0.1.weight', 'features.6.conv.0.1.bias', 'features.6.conv.0.1.running_mean', 'features.6.conv.0.1.running_var', 'features.6.conv.0.1.num_batches_tracked', 'features.6.conv.1.0.weight', 'features.6.conv.1.1.weight', 'features.6.conv.1.1.bias', 'features.6.conv.1.1.running_mean', 'features.6.conv.1.1.running_var', 'features.6.conv.1.1.num_batches_tracked', 'features.6.conv.2.weight', 'features.6.conv.3.weight', 'features.6.conv.3.bias', 'features.6.conv.3.running_mean', 'features.6.conv.3.running_var', 'features.6.conv.3.num_batches_tracked', 'features.7.conv.0.0.weight', 'features.7.conv.0.1.weight', 'features.7.conv.0.1.bias', 'features.7.conv.0.1.running_mean', 'features.7.conv.0.1.running_var', 'features.7.conv.0.1.num_batches_tracked', 'features.7.conv.1.0.weight', 'features.7.conv.1.1.weight', 'features.7.conv.1.1.bias', 'features.7.conv.1.1.running_mean', 'features.7.conv.1.1.running_var', 'features.7.conv.1.1.num_batches_tracked', 'features.7.conv.2.weight', 'features.7.conv.3.weight', 'features.7.conv.3.bias', 'features.7.conv.3.running_mean', 'features.7.conv.3.running_var', 'features.7.conv.3.num_batches_tracked', 'features.8.conv.0.0.weight', 'features.8.conv.0.1.weight', 'features.8.conv.0.1.bias', 'features.8.conv.0.1.running_mean', 'features.8.conv.0.1.running_var', 'features.8.conv.0.1.num_batches_tracked', 'features.8.conv.1.0.weight', 'features.8.conv.1.1.weight', 'features.8.conv.1.1.bias', 'features.8.conv.1.1.running_mean', 'features.8.conv.1.1.running_var', 'features.8.conv.1.1.num_batches_tracked', 'features.8.conv.2.weight', 'features.8.conv.3.weight', 'features.8.conv.3.bias', 'features.8.conv.3.running_mean', 'features.8.conv.3.running_var', 'features.8.conv.3.num_batches_tracked', 'features.9.conv.0.0.weight', 'features.9.conv.0.1.weight', 'features.9.conv.0.1.bias', 'features.9.conv.0.1.running_mean', 'features.9.conv.0.1.running_var', 'features.9.conv.0.1.num_batches_tracked', 'features.9.conv.1.0.weight', 'features.9.conv.1.1.weight', 'features.9.conv.1.1.bias', 'features.9.conv.1.1.running_mean', 'features.9.conv.1.1.running_var', 'features.9.conv.1.1.num_batches_tracked', 'features.9.conv.2.weight', 'features.9.conv.3.weight', 'features.9.conv.3.bias', 'features.9.conv.3.running_mean', 'features.9.conv.3.running_var', 'features.9.conv.3.num_batches_tracked', 'features.10.conv.0.0.weight', 'features.10.conv.0.1.weight', 'features.10.conv.0.1.bias', 'features.10.conv.0.1.running_mean', 'features.10.conv.0.1.running_var', 'features.10.conv.0.1.num_batches_tracked', 'features.10.conv.1.0.weight', 'features.10.conv.1.1.weight', 'features.10.conv.1.1.bias', 'features.10.conv.1.1.running_mean', 'features.10.conv.1.1.running_var', 'features.10.conv.1.1.num_batches_tracked', 'features.10.conv.2.weight', 'features.10.conv.3.weight', 'features.10.conv.3.bias', 'features.10.conv.3.running_mean', 'features.10.conv.3.running_var', 'features.10.conv.3.num_batches_tracked', 'features.11.conv.0.0.weight', 'features.11.conv.0.1.weight', 'features.11.conv.0.1.bias', 'features.11.conv.0.1.running_mean', 'features.11.conv.0.1.running_var', 'features.11.conv.0.1.num_batches_tracked', 'features.11.conv.1.0.weight', 'features.11.conv.1.1.weight', 'features.11.conv.1.1.bias', 'features.11.conv.1.1.running_mean', 'features.11.conv.1.1.running_var', 'features.11.conv.1.1.num_batches_tracked', 'features.11.conv.2.weight', 'features.11.conv.3.weight', 'features.11.conv.3.bias', 'features.11.conv.3.running_mean', 'features.11.conv.3.running_var', 'features.11.conv.3.num_batches_tracked', 'features.12.conv.0.0.weight', 'features.12.conv.0.1.weight', 'features.12.conv.0.1.bias', 'features.12.conv.0.1.running_mean', 'features.12.conv.0.1.running_var', 'features.12.conv.0.1.num_batches_tracked', 'features.12.conv.1.0.weight', 'features.12.conv.1.1.weight', 'features.12.conv.1.1.bias', 'features.12.conv.1.1.running_mean', 'features.12.conv.1.1.running_var', 'features.12.conv.1.1.num_batches_tracked', 'features.12.conv.2.weight', 'features.12.conv.3.weight', 'features.12.conv.3.bias', 'features.12.conv.3.running_mean', 'features.12.conv.3.running_var', 'features.12.conv.3.num_batches_tracked', 'features.13.conv.0.0.weight', 'features.13.conv.0.1.weight', 'features.13.conv.0.1.bias', 'features.13.conv.0.1.running_mean', 'features.13.conv.0.1.running_var', 'features.13.conv.0.1.num_batches_tracked', 'features.13.conv.1.0.weight', 'features.13.conv.1.1.weight', 'features.13.conv.1.1.bias', 'features.13.conv.1.1.running_mean', 'features.13.conv.1.1.running_var', 'features.13.conv.1.1.num_batches_tracked', 'features.13.conv.2.weight', 'features.13.conv.3.weight', 'features.13.conv.3.bias', 'features.13.conv.3.running_mean', 'features.13.conv.3.running_var', 'features.13.conv.3.num_batches_tracked', 'features.14.conv.0.0.weight', 'features.14.conv.0.1.weight', 'features.14.conv.0.1.bias', 'features.14.conv.0.1.running_mean', 'features.14.conv.0.1.running_var', 'features.14.conv.0.1.num_batches_tracked', 'features.14.conv.1.0.weight', 'features.14.conv.1.1.weight', 'features.14.conv.1.1.bias', 'features.14.conv.1.1.running_mean', 'features.14.conv.1.1.running_var', 'features.14.conv.1.1.num_batches_tracked', 'features.14.conv.2.weight', 'features.14.conv.3.weight', 'features.14.conv.3.bias', 'features.14.conv.3.running_mean', 'features.14.conv.3.running_var', 'features.14.conv.3.num_batches_tracked', 'features.15.conv.0.0.weight', 'features.15.conv.0.1.weight', 'features.15.conv.0.1.bias', 'features.15.conv.0.1.running_mean', 'features.15.conv.0.1.running_var', 'features.15.conv.0.1.num_batches_tracked', 'features.15.conv.1.0.weight', 'features.15.conv.1.1.weight', 'features.15.conv.1.1.bias', 'features.15.conv.1.1.running_mean', 'features.15.conv.1.1.running_var', 'features.15.conv.1.1.num_batches_tracked', 'features.15.conv.2.weight', 'features.15.conv.3.weight', 'features.15.conv.3.bias', 'features.15.conv.3.running_mean', 'features.15.conv.3.running_var', 'features.15.conv.3.num_batches_tracked', 'features.16.conv.0.0.weight', 'features.16.conv.0.1.weight', 'features.16.conv.0.1.bias', 'features.16.conv.0.1.running_mean', 'features.16.conv.0.1.running_var', 'features.16.conv.0.1.num_batches_tracked', 'features.16.conv.1.0.weight', 'features.16.conv.1.1.weight', 'features.16.conv.1.1.bias', 'features.16.conv.1.1.running_mean', 'features.16.conv.1.1.running_var', 'features.16.conv.1.1.num_batches_tracked', 'features.16.conv.2.weight', 'features.16.conv.3.weight', 'features.16.conv.3.bias', 'features.16.conv.3.running_mean', 'features.16.conv.3.running_var', 'features.16.conv.3.num_batches_tracked', 'features.17.conv.0.0.weight', 'features.17.conv.0.1.weight', 'features.17.conv.0.1.bias', 'features.17.conv.0.1.running_mean', 'features.17.conv.0.1.running_var', 'features.17.conv.0.1.num_batches_tracked', 'features.17.conv.1.0.weight', 'features.17.conv.1.1.weight', 'features.17.conv.1.1.bias', 'features.17.conv.1.1.running_mean', 'features.17.conv.1.1.running_var', 'features.17.conv.1.1.num_batches_tracked', 'features.17.conv.2.weight', 'features.17.conv.3.weight', 'features.17.conv.3.bias', 'features.17.conv.3.running_mean', 'features.17.conv.3.running_var', 'features.17.conv.3.num_batches_tracked', 'features.18.0.weight', 'features.18.1.weight', 'features.18.1.bias', 'features.18.1.running_mean', 'features.18.1.running_var', 'features.18.1.num_batches_tracked', 'classifier.1.weight', 'classifier.1.bias'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_FAT.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mag norm \n",
    "mag_norm_FedAvg2FAT = []\n",
    "for key in desired_keys: #params_FAT:\n",
    "\n",
    "    diff = params_FAT[key] - params_FedAvg[key]\n",
    "    l2_norm = torch.norm(diff, p=2)\n",
    "\n",
    "    mag_norm_FedAvg2FAT += [diff/torch.norm(diff,p=2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.170 | Train Acc: 95.705% |Test Loss: 0.602 | Test Acc: 80.222% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "################################################################################\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.155 | Train Acc: 96.236% |Test Loss: 0.585 | Test Acc: 80.878% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "################################################################################\n",
      "++++++++++++++++++++++++++++++\n",
      "Global..\n",
      "Train Loss: 0.155 | Train Acc: 96.236% |Test Loss: 0.585 | Test Acc: 80.878% |\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "################################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4125, device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform 50 rounds of full overfitting on benign data on 200R FAT model\n",
    "num_rounds = 10\n",
    "\n",
    "# Test performance of aggregator on data \n",
    "aggregator.load_state(dir_path = save_path_FAT)\n",
    "aggregator.update_clients()\n",
    "aggregator.write_logs()\n",
    "model_FAT = pull_model_from_agg(aggregator)\n",
    "print(get_adv_acc(aggregator, model_FAT))\n",
    "\n",
    "for i in range(num_rounds):\n",
    "    print(i)\n",
    "    aggregator.mix()\n",
    "aggregator.update_clients()\n",
    "aggregator.write_logs()\n",
    "\n",
    "model_overfit = pull_model_from_agg(aggregator)\n",
    "get_adv_acc(aggregator, model_overfit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_adv_acc(aggregator, model_overfit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedEM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
